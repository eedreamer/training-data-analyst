{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sequence to Sequence Learning with Tensor2Tensor",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eedreamer/training-data-analyst/blob/master/Sequence_to_Sequence_Learning_with_Tensor2Tensor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "odi2vIMHC3Rm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sequence to Sequence Learning with Tensor2Tensor\n"
      ]
    },
    {
      "metadata": {
        "id": "ir4JzdPlsD9M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook was created for PhD Open lectures given in June 2018 at the University of Warsaw. The slides for the lectures are available [here](http://phdopen.mimuw.edu.pl/lato18/w5s/DeepLearning.pdf) and the full recording [here on YouTube](https://www.youtube.com/channel/UCvMN-HLvvVa6lUXijCKFlqQ) - take a look at it if you need more explanation!"
      ]
    },
    {
      "metadata": {
        "id": "OPGni6fuvoTj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install deps.\n",
        "!pip install -q -U tensor2tensor\n",
        "!pip install -q tensorflow matplotlib\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xN32gDt-Lj2T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#t2t-trainer  --generate_data \\\n",
        "#  --data_dir=~/t2t_data \\\n",
        "#  --output_dir=~/t2t_train/mnist \\\n",
        " # --problem=image_mnist \\\n",
        " # --model=shake_shake \\\n",
        " # --hparams_set=shake_shake_quick \\\n",
        " # --train_steps=1000 \\\n",
        " # --eval_steps=100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oILRLCWN_16u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Imports we need.\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import collections\n",
        "import random\n",
        "import six\n",
        "\n",
        "from tensor2tensor import models\n",
        "from tensor2tensor import problems\n",
        "from tensor2tensor.layers import common_attention\n",
        "from tensor2tensor.layers import common_layers\n",
        "from tensor2tensor.utils import trainer_lib\n",
        "from tensor2tensor.utils import t2t_model\n",
        "from tensor2tensor.utils import registry\n",
        "from tensor2tensor.utils import metrics\n",
        "from tensor2tensor.utils import learning_rate\n",
        "from tensor2tensor.utils import optimize\n",
        "\n",
        "# TF session\n",
        "sess = tf.Session()\n",
        "\n",
        "# Other setup\n",
        "Modes = tf.estimator.ModeKeys\n",
        "\n",
        "# Setup some directories\n",
        "data_dir = os.path.expanduser(\"~/t2t/data\")\n",
        "tmp_dir = os.path.expanduser(\"~/t2t/tmp\")\n",
        "train_dir = os.path.expanduser(\"~/t2t/train\")\n",
        "checkpoint_dir = os.path.expanduser(\"~/t2t/checkpoints\")\n",
        "tf.gfile.MakeDirs(data_dir)\n",
        "tf.gfile.MakeDirs(tmp_dir)\n",
        "tf.gfile.MakeDirs(train_dir)\n",
        "tf.gfile.MakeDirs(checkpoint_dir)\n",
        "gs_data_dir = \"gs://tensor2tensor-data\"\n",
        "gs_ckpt_dir = \"gs://tensor2tensor-checkpoints/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0a69r1KDiZDe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Download MNIST and inspect it"
      ]
    },
    {
      "metadata": {
        "id": "JKc2uSk6WX5e",
        "colab_type": "code",
        "outputId": "a7138ea6-caa9-4362-e5f4-b892d5b3c0ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "cell_type": "code",
      "source": [
        "# Fetch the MNIST problem\n",
        "print(problems.available())\n",
        "mnist_problem = problems.problem(\"image_mnist\")\n",
        "# The generate_data method of a problem will download data and process it into\n",
        "# a standard format ready for training and evaluation.\n",
        "mnist_problem.generate_data(data_dir, tmp_dir)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['algorithmic_addition_binary40', 'algorithmic_addition_decimal40', 'algorithmic_cipher_shift200', 'algorithmic_cipher_shift5', 'algorithmic_cipher_vigenere200', 'algorithmic_cipher_vigenere5', 'algorithmic_identity_binary40', 'algorithmic_identity_decimal40', 'algorithmic_multiplication_binary40', 'algorithmic_multiplication_decimal40', 'algorithmic_reverse_binary40', 'algorithmic_reverse_binary40_test', 'algorithmic_reverse_decimal40', 'algorithmic_reverse_nlplike32k', 'algorithmic_reverse_nlplike8k', 'algorithmic_shift_decimal40', 'algorithmic_sort_problem', 'audio_timit_characters_tune', 'audio_timit_tokens8k_test', 'audio_timit_tokens8k_tune', 'babi_qa_concat_all_tasks_10k', 'babi_qa_concat_all_tasks_1k', 'babi_qa_concat_task10_10k', 'babi_qa_concat_task10_1k', 'babi_qa_concat_task11_10k', 'babi_qa_concat_task11_1k', 'babi_qa_concat_task12_10k', 'babi_qa_concat_task12_1k', 'babi_qa_concat_task13_10k', 'babi_qa_concat_task13_1k', 'babi_qa_concat_task14_10k', 'babi_qa_concat_task14_1k', 'babi_qa_concat_task15_10k', 'babi_qa_concat_task15_1k', 'babi_qa_concat_task16_10k', 'babi_qa_concat_task16_1k', 'babi_qa_concat_task17_10k', 'babi_qa_concat_task17_1k', 'babi_qa_concat_task18_10k', 'babi_qa_concat_task18_1k', 'babi_qa_concat_task19_10k', 'babi_qa_concat_task19_1k', 'babi_qa_concat_task1_10k', 'babi_qa_concat_task1_1k', 'babi_qa_concat_task20_10k', 'babi_qa_concat_task20_1k', 'babi_qa_concat_task2_10k', 'babi_qa_concat_task2_1k', 'babi_qa_concat_task3_10k', 'babi_qa_concat_task3_1k', 'babi_qa_concat_task4_10k', 'babi_qa_concat_task4_1k', 'babi_qa_concat_task5_10k', 'babi_qa_concat_task5_1k', 'babi_qa_concat_task6_10k', 'babi_qa_concat_task6_1k', 'babi_qa_concat_task7_10k', 'babi_qa_concat_task7_1k', 'babi_qa_concat_task8_10k', 'babi_qa_concat_task8_1k', 'babi_qa_concat_task9_10k', 'babi_qa_concat_task9_1k', 'cola', 'cola_characters', 'common_voice', 'common_voice_clean', 'common_voice_noisy', 'common_voice_train_full_test_clean', 'genomics_expression_cage10', 'genomics_expression_gm12878', 'genomics_expression_l262k', 'github_function_docstring', 'gym_air_raid-v0_random', 'gym_air_raid-v4_random', 'gym_air_raid_deterministic-v0_random', 'gym_air_raid_deterministic-v4_random', 'gym_air_raid_no_frameskip-v0_random', 'gym_air_raid_no_frameskip-v4_random', 'gym_alien-v0_random', 'gym_alien-v4_random', 'gym_alien_deterministic-v0_random', 'gym_alien_deterministic-v4_random', 'gym_alien_no_frameskip-v0_random', 'gym_alien_no_frameskip-v4_random', 'gym_amidar-v0_random', 'gym_amidar-v4_random', 'gym_amidar_deterministic-v0_random', 'gym_amidar_deterministic-v4_random', 'gym_amidar_no_frameskip-v0_random', 'gym_amidar_no_frameskip-v4_random', 'gym_assault-v0_random', 'gym_assault-v4_random', 'gym_assault_deterministic-v0_random', 'gym_assault_deterministic-v4_random', 'gym_assault_no_frameskip-v0_random', 'gym_assault_no_frameskip-v4_random', 'gym_asterix-v0_random', 'gym_asterix-v4_random', 'gym_asterix_deterministic-v0_random', 'gym_asterix_deterministic-v4_random', 'gym_asterix_no_frameskip-v0_random', 'gym_asterix_no_frameskip-v4_random', 'gym_asteroids-v0_random', 'gym_asteroids-v4_random', 'gym_asteroids_deterministic-v0_random', 'gym_asteroids_deterministic-v4_random', 'gym_asteroids_no_frameskip-v0_random', 'gym_asteroids_no_frameskip-v4_random', 'gym_atlantis-v0_random', 'gym_atlantis-v4_random', 'gym_atlantis_deterministic-v0_random', 'gym_atlantis_deterministic-v4_random', 'gym_atlantis_no_frameskip-v0_random', 'gym_atlantis_no_frameskip-v4_random', 'gym_bank_heist-v0_random', 'gym_bank_heist-v4_random', 'gym_bank_heist_deterministic-v0_random', 'gym_bank_heist_deterministic-v4_random', 'gym_bank_heist_no_frameskip-v0_random', 'gym_bank_heist_no_frameskip-v4_random', 'gym_battle_zone-v0_random', 'gym_battle_zone-v4_random', 'gym_battle_zone_deterministic-v0_random', 'gym_battle_zone_deterministic-v4_random', 'gym_battle_zone_no_frameskip-v0_random', 'gym_battle_zone_no_frameskip-v4_random', 'gym_beam_rider-v0_random', 'gym_beam_rider-v4_random', 'gym_beam_rider_deterministic-v0_random', 'gym_beam_rider_deterministic-v4_random', 'gym_beam_rider_no_frameskip-v0_random', 'gym_beam_rider_no_frameskip-v4_random', 'gym_berzerk-v0_random', 'gym_berzerk-v4_random', 'gym_berzerk_deterministic-v0_random', 'gym_berzerk_deterministic-v4_random', 'gym_berzerk_no_frameskip-v0_random', 'gym_berzerk_no_frameskip-v4_random', 'gym_bowling-v0_random', 'gym_bowling-v4_random', 'gym_bowling_deterministic-v0_random', 'gym_bowling_deterministic-v4_random', 'gym_bowling_no_frameskip-v0_random', 'gym_bowling_no_frameskip-v4_random', 'gym_boxing-v0_random', 'gym_boxing-v4_random', 'gym_boxing_deterministic-v0_random', 'gym_boxing_deterministic-v4_random', 'gym_boxing_no_frameskip-v0_random', 'gym_boxing_no_frameskip-v4_random', 'gym_breakout-v0_random', 'gym_breakout-v4_random', 'gym_breakout_deterministic-v0_random', 'gym_breakout_deterministic-v4_random', 'gym_breakout_no_frameskip-v0_random', 'gym_breakout_no_frameskip-v4_random', 'gym_carnival-v0_random', 'gym_carnival-v4_random', 'gym_carnival_deterministic-v0_random', 'gym_carnival_deterministic-v4_random', 'gym_carnival_no_frameskip-v0_random', 'gym_carnival_no_frameskip-v4_random', 'gym_centipede-v0_random', 'gym_centipede-v4_random', 'gym_centipede_deterministic-v0_random', 'gym_centipede_deterministic-v4_random', 'gym_centipede_no_frameskip-v0_random', 'gym_centipede_no_frameskip-v4_random', 'gym_chopper_command-v0_random', 'gym_chopper_command-v4_random', 'gym_chopper_command_deterministic-v0_random', 'gym_chopper_command_deterministic-v4_random', 'gym_chopper_command_no_frameskip-v0_random', 'gym_chopper_command_no_frameskip-v4_random', 'gym_crazy_climber-v0_random', 'gym_crazy_climber-v4_random', 'gym_crazy_climber_deterministic-v0_random', 'gym_crazy_climber_deterministic-v4_random', 'gym_crazy_climber_no_frameskip-v0_random', 'gym_crazy_climber_no_frameskip-v4_random', 'gym_demon_attack-v0_random', 'gym_demon_attack-v4_random', 'gym_demon_attack_deterministic-v0_random', 'gym_demon_attack_deterministic-v4_random', 'gym_demon_attack_no_frameskip-v0_random', 'gym_demon_attack_no_frameskip-v4_random', 'gym_double_dunk-v0_random', 'gym_double_dunk-v4_random', 'gym_double_dunk_deterministic-v0_random', 'gym_double_dunk_deterministic-v4_random', 'gym_double_dunk_no_frameskip-v0_random', 'gym_double_dunk_no_frameskip-v4_random', 'gym_elevator_action-v0_random', 'gym_elevator_action-v4_random', 'gym_elevator_action_deterministic-v0_random', 'gym_elevator_action_deterministic-v4_random', 'gym_elevator_action_no_frameskip-v0_random', 'gym_elevator_action_no_frameskip-v4_random', 'gym_enduro-v0_random', 'gym_enduro-v4_random', 'gym_enduro_deterministic-v0_random', 'gym_enduro_deterministic-v4_random', 'gym_enduro_no_frameskip-v0_random', 'gym_enduro_no_frameskip-v4_random', 'gym_fishing_derby-v0_random', 'gym_fishing_derby-v4_random', 'gym_fishing_derby_deterministic-v0_random', 'gym_fishing_derby_deterministic-v4_random', 'gym_fishing_derby_no_frameskip-v0_random', 'gym_fishing_derby_no_frameskip-v4_random', 'gym_freeway-v0_random', 'gym_freeway-v4_random', 'gym_freeway_deterministic-v0_random', 'gym_freeway_deterministic-v4_random', 'gym_freeway_no_frameskip-v0_random', 'gym_freeway_no_frameskip-v4_random', 'gym_frostbite-v0_random', 'gym_frostbite-v4_random', 'gym_frostbite_deterministic-v0_random', 'gym_frostbite_deterministic-v4_random', 'gym_frostbite_no_frameskip-v0_random', 'gym_frostbite_no_frameskip-v4_random', 'gym_gopher-v0_random', 'gym_gopher-v4_random', 'gym_gopher_deterministic-v0_random', 'gym_gopher_deterministic-v4_random', 'gym_gopher_no_frameskip-v0_random', 'gym_gopher_no_frameskip-v4_random', 'gym_gravitar-v0_random', 'gym_gravitar-v4_random', 'gym_gravitar_deterministic-v0_random', 'gym_gravitar_deterministic-v4_random', 'gym_gravitar_no_frameskip-v0_random', 'gym_gravitar_no_frameskip-v4_random', 'gym_hero-v0_random', 'gym_hero-v4_random', 'gym_hero_deterministic-v0_random', 'gym_hero_deterministic-v4_random', 'gym_hero_no_frameskip-v0_random', 'gym_hero_no_frameskip-v4_random', 'gym_ice_hockey-v0_random', 'gym_ice_hockey-v4_random', 'gym_ice_hockey_deterministic-v0_random', 'gym_ice_hockey_deterministic-v4_random', 'gym_ice_hockey_no_frameskip-v0_random', 'gym_ice_hockey_no_frameskip-v4_random', 'gym_jamesbond-v0_random', 'gym_jamesbond-v4_random', 'gym_jamesbond_deterministic-v0_random', 'gym_jamesbond_deterministic-v4_random', 'gym_jamesbond_no_frameskip-v0_random', 'gym_jamesbond_no_frameskip-v4_random', 'gym_journey_escape-v0_random', 'gym_journey_escape-v4_random', 'gym_journey_escape_deterministic-v0_random', 'gym_journey_escape_deterministic-v4_random', 'gym_journey_escape_no_frameskip-v0_random', 'gym_journey_escape_no_frameskip-v4_random', 'gym_kangaroo-v0_random', 'gym_kangaroo-v4_random', 'gym_kangaroo_deterministic-v0_random', 'gym_kangaroo_deterministic-v4_random', 'gym_kangaroo_no_frameskip-v0_random', 'gym_kangaroo_no_frameskip-v4_random', 'gym_krull-v0_random', 'gym_krull-v4_random', 'gym_krull_deterministic-v0_random', 'gym_krull_deterministic-v4_random', 'gym_krull_no_frameskip-v0_random', 'gym_krull_no_frameskip-v4_random', 'gym_kung_fu_master-v0_random', 'gym_kung_fu_master-v4_random', 'gym_kung_fu_master_deterministic-v0_random', 'gym_kung_fu_master_deterministic-v4_random', 'gym_kung_fu_master_no_frameskip-v0_random', 'gym_kung_fu_master_no_frameskip-v4_random', 'gym_montezuma_revenge-v0_random', 'gym_montezuma_revenge-v4_random', 'gym_montezuma_revenge_deterministic-v0_random', 'gym_montezuma_revenge_deterministic-v4_random', 'gym_montezuma_revenge_no_frameskip-v0_random', 'gym_montezuma_revenge_no_frameskip-v4_random', 'gym_ms_pacman-v0_random', 'gym_ms_pacman-v4_random', 'gym_ms_pacman_deterministic-v0_random', 'gym_ms_pacman_deterministic-v4_random', 'gym_ms_pacman_no_frameskip-v0_random', 'gym_ms_pacman_no_frameskip-v4_random', 'gym_name_this_game-v0_random', 'gym_name_this_game-v4_random', 'gym_name_this_game_deterministic-v0_random', 'gym_name_this_game_deterministic-v4_random', 'gym_name_this_game_no_frameskip-v0_random', 'gym_name_this_game_no_frameskip-v4_random', 'gym_phoenix-v0_random', 'gym_phoenix-v4_random', 'gym_phoenix_deterministic-v0_random', 'gym_phoenix_deterministic-v4_random', 'gym_phoenix_no_frameskip-v0_random', 'gym_phoenix_no_frameskip-v4_random', 'gym_pitfall-v0_random', 'gym_pitfall-v4_random', 'gym_pitfall_deterministic-v0_random', 'gym_pitfall_deterministic-v4_random', 'gym_pitfall_no_frameskip-v0_random', 'gym_pitfall_no_frameskip-v4_random', 'gym_pong-v0_random', 'gym_pong-v4_random', 'gym_pong_deterministic-v0_random', 'gym_pong_deterministic-v4_random', 'gym_pong_no_frameskip-v0_random', 'gym_pong_no_frameskip-v4_random', 'gym_pooyan-v0_random', 'gym_pooyan-v4_random', 'gym_pooyan_deterministic-v0_random', 'gym_pooyan_deterministic-v4_random', 'gym_pooyan_no_frameskip-v0_random', 'gym_pooyan_no_frameskip-v4_random', 'gym_private_eye-v0_random', 'gym_private_eye-v4_random', 'gym_private_eye_deterministic-v0_random', 'gym_private_eye_deterministic-v4_random', 'gym_private_eye_no_frameskip-v0_random', 'gym_private_eye_no_frameskip-v4_random', 'gym_qbert-v0_random', 'gym_qbert-v4_random', 'gym_qbert_deterministic-v0_random', 'gym_qbert_deterministic-v4_random', 'gym_qbert_no_frameskip-v0_random', 'gym_qbert_no_frameskip-v4_random', 'gym_riverraid-v0_random', 'gym_riverraid-v4_random', 'gym_riverraid_deterministic-v0_random', 'gym_riverraid_deterministic-v4_random', 'gym_riverraid_no_frameskip-v0_random', 'gym_riverraid_no_frameskip-v4_random', 'gym_road_runner-v0_random', 'gym_road_runner-v4_random', 'gym_road_runner_deterministic-v0_random', 'gym_road_runner_deterministic-v4_random', 'gym_road_runner_no_frameskip-v0_random', 'gym_road_runner_no_frameskip-v4_random', 'gym_robotank-v0_random', 'gym_robotank-v4_random', 'gym_robotank_deterministic-v0_random', 'gym_robotank_deterministic-v4_random', 'gym_robotank_no_frameskip-v0_random', 'gym_robotank_no_frameskip-v4_random', 'gym_seaquest-v0_random', 'gym_seaquest-v4_random', 'gym_seaquest_deterministic-v0_random', 'gym_seaquest_deterministic-v4_random', 'gym_seaquest_no_frameskip-v0_random', 'gym_seaquest_no_frameskip-v4_random', 'gym_skiing-v0_random', 'gym_skiing-v4_random', 'gym_skiing_deterministic-v0_random', 'gym_skiing_deterministic-v4_random', 'gym_skiing_no_frameskip-v0_random', 'gym_skiing_no_frameskip-v4_random', 'gym_solaris-v0_random', 'gym_solaris-v4_random', 'gym_solaris_deterministic-v0_random', 'gym_solaris_deterministic-v4_random', 'gym_solaris_no_frameskip-v0_random', 'gym_solaris_no_frameskip-v4_random', 'gym_space_invaders-v0_random', 'gym_space_invaders-v4_random', 'gym_space_invaders_deterministic-v0_random', 'gym_space_invaders_deterministic-v4_random', 'gym_space_invaders_no_frameskip-v0_random', 'gym_space_invaders_no_frameskip-v4_random', 'gym_star_gunner-v0_random', 'gym_star_gunner-v4_random', 'gym_star_gunner_deterministic-v0_random', 'gym_star_gunner_deterministic-v4_random', 'gym_star_gunner_no_frameskip-v0_random', 'gym_star_gunner_no_frameskip-v4_random', 'gym_tennis-v0_random', 'gym_tennis-v4_random', 'gym_tennis_deterministic-v0_random', 'gym_tennis_deterministic-v4_random', 'gym_tennis_no_frameskip-v0_random', 'gym_tennis_no_frameskip-v4_random', 'gym_time_pilot-v0_random', 'gym_time_pilot-v4_random', 'gym_time_pilot_deterministic-v0_random', 'gym_time_pilot_deterministic-v4_random', 'gym_time_pilot_no_frameskip-v0_random', 'gym_time_pilot_no_frameskip-v4_random', 'gym_tutankham-v0_random', 'gym_tutankham-v4_random', 'gym_tutankham_deterministic-v0_random', 'gym_tutankham_deterministic-v4_random', 'gym_tutankham_no_frameskip-v0_random', 'gym_tutankham_no_frameskip-v4_random', 'gym_up_n_down-v0_random', 'gym_up_n_down-v4_random', 'gym_up_n_down_deterministic-v0_random', 'gym_up_n_down_deterministic-v4_random', 'gym_up_n_down_no_frameskip-v0_random', 'gym_up_n_down_no_frameskip-v4_random', 'gym_venture-v0_random', 'gym_venture-v4_random', 'gym_venture_deterministic-v0_random', 'gym_venture_deterministic-v4_random', 'gym_venture_no_frameskip-v0_random', 'gym_venture_no_frameskip-v4_random', 'gym_video_pinball-v0_random', 'gym_video_pinball-v4_random', 'gym_video_pinball_deterministic-v0_random', 'gym_video_pinball_deterministic-v4_random', 'gym_video_pinball_no_frameskip-v0_random', 'gym_video_pinball_no_frameskip-v4_random', 'gym_wizard_of_wor-v0_random', 'gym_wizard_of_wor-v4_random', 'gym_wizard_of_wor_deterministic-v0_random', 'gym_wizard_of_wor_deterministic-v4_random', 'gym_wizard_of_wor_no_frameskip-v0_random', 'gym_wizard_of_wor_no_frameskip-v4_random', 'gym_yars_revenge-v0_random', 'gym_yars_revenge-v4_random', 'gym_yars_revenge_deterministic-v0_random', 'gym_yars_revenge_deterministic-v4_random', 'gym_yars_revenge_no_frameskip-v0_random', 'gym_yars_revenge_no_frameskip-v4_random', 'gym_zaxxon-v0_random', 'gym_zaxxon-v4_random', 'gym_zaxxon_deterministic-v0_random', 'gym_zaxxon_deterministic-v4_random', 'gym_zaxxon_no_frameskip-v0_random', 'gym_zaxxon_no_frameskip-v4_random', 'image_celeba', 'image_celeba32', 'image_celeba64', 'image_celeba_multi_resolution', 'image_celebahq128', 'image_celebahq128_dmol', 'image_celebahq256', 'image_celebahq256_dmol', 'image_cifar10', 'image_cifar100', 'image_cifar100_plain', 'image_cifar100_plain8', 'image_cifar100_plain_gen', 'image_cifar100_tune', 'image_cifar10_plain', 'image_cifar10_plain8', 'image_cifar10_plain_gen', 'image_cifar10_plain_gen_dmol', 'image_cifar10_plain_random_shift', 'image_cifar10_tune', 'image_cifar20', 'image_cifar20_plain', 'image_cifar20_plain8', 'image_cifar20_plain_gen', 'image_cifar20_tune', 'image_fashion_mnist', 'image_fsns', 'image_imagenet', 'image_imagenet224', 'image_imagenet32', 'image_imagenet32_gen', 'image_imagenet32_small', 'image_imagenet64', 'image_imagenet64_gen', 'image_imagenet_multi_resolution_gen', 'image_lsun_bedrooms', 'image_mnist', 'image_mnist_tune', 'image_ms_coco_characters', 'image_ms_coco_tokens32k', 'image_text_ms_coco', 'image_text_ms_coco_multi_resolution', 'image_vqav2_rcnn_feature_tokens10k_labels3k', 'image_vqav2_tokens10k_labels3k', 'img2img_allen_brain', 'img2img_allen_brain_dim16to16_paint1', 'img2img_allen_brain_dim48to64', 'img2img_allen_brain_dim8to32', 'img2img_celeba', 'img2img_celeba64', 'img2img_cifar10', 'img2img_cifar100', 'img2img_imagenet', 'lambada_lm', 'lambada_lm_control', 'lambada_rc', 'lambada_rc_control', 'languagemodel_lm1b32k', 'languagemodel_lm1b32k_packed', 'languagemodel_lm1b8k', 'languagemodel_lm1b8k_packed', 'languagemodel_lm1b_characters', 'languagemodel_lm1b_characters_packed', 'languagemodel_lm1b_multi_nli', 'languagemodel_lm1b_multi_nli_subwords', 'languagemodel_lm1b_sentiment_imdb', 'languagemodel_ptb10k', 'languagemodel_ptb_characters', 'languagemodel_wiki_noref_v128k_l1k', 'languagemodel_wiki_noref_v32k_l1k', 'languagemodel_wiki_noref_v8k_l16k', 'languagemodel_wiki_noref_v8k_l1k', 'languagemodel_wiki_scramble_l128', 'languagemodel_wiki_scramble_l1k', 'languagemodel_wiki_xml_v8k_l1k', 'languagemodel_wiki_xml_v8k_l4k', 'languagemodel_wikitext103', 'languagemodel_wikitext103_characters', 'librispeech', 'librispeech_clean', 'librispeech_clean_small', 'librispeech_noisy', 'librispeech_train_full_test_clean', 'msr_paraphrase_corpus', 'msr_paraphrase_corpus_characters', 'multi_nli', 'multi_nli_characters', 'multi_nli_shared_vocab', 'ocr_test', 'paraphrase_generation_ms_coco_problem1d', 'paraphrase_generation_ms_coco_problem1d_characters', 'paraphrase_generation_ms_coco_problem2d', 'paraphrase_generation_ms_coco_problem2d_characters', 'parsing_english_ptb16k', 'parsing_english_ptb8k', 'parsing_icelandic16k', 'program_search_algolisp', 'programming_desc2code_cpp', 'programming_desc2code_py', 'question_nli', 'question_nli_characters', 'quora_question_pairs', 'quora_question_pairs_characters', 'rte', 'rte_characters', 'sci_tail', 'sci_tail_characters', 'sci_tail_shared_vocab', 'sentiment_imdb', 'sentiment_imdb_characters', 'sentiment_sst_binary', 'sentiment_sst_binary_characters', 'squad', 'squad_concat', 'squad_concat_positioned', 'stanford_nli', 'stanford_nli_characters', 'stanford_nli_shared_vocab', 'style_transfer_modern_to_shakespeare', 'style_transfer_modern_to_shakespeare_characters', 'style_transfer_shakespeare_to_modern', 'style_transfer_shakespeare_to_modern_characters', 'summarize_cnn_dailymail32k', 'sva_language_modeling', 'sva_number_prediction', 'text2text_copyable_tokens', 'text2text_tmpdir', 'text2text_tmpdir_tokens', 'timeseries_synthetic_data_series10_samples100k', 'timeseries_toy_problem', 'tiny_algo', 'translate_encs_wmt32k', 'translate_encs_wmt_characters', 'translate_ende_wmt32k', 'translate_ende_wmt32k_packed', 'translate_ende_wmt8k', 'translate_ende_wmt8k_packed', 'translate_ende_wmt_bpe32k', 'translate_ende_wmt_characters', 'translate_enet_wmt32k', 'translate_enet_wmt_characters', 'translate_enfr_wmt32k', 'translate_enfr_wmt32k_packed', 'translate_enfr_wmt8k', 'translate_enfr_wmt_characters', 'translate_enfr_wmt_small32k', 'translate_enfr_wmt_small8k', 'translate_enfr_wmt_small_characters', 'translate_enid_iwslt32k', 'translate_enmk_setimes32k', 'translate_enmk_setimes_characters', 'translate_envi_iwslt32k', 'translate_enzh_wmt32k', 'translate_enzh_wmt8k', 'video_bair_robot_pushing', 'video_bair_robot_pushing_with_actions', 'video_google_robot_pushing', 'video_stochastic_shapes10k', 'video_twentybn', 'wikisum_commoncrawl', 'wikisum_commoncrawl_lead_section', 'wikisum_web', 'wikisum_web_lead_section', 'winograd_nli', 'winograd_nli_characters', 'wsj_parsing']\n",
            "INFO:tensorflow:Not downloading, file already found: /root/t2t/tmp/train-images-idx3-ubyte.gz\n",
            "INFO:tensorflow:Not downloading, file already found: /root/t2t/tmp/train-labels-idx1-ubyte.gz\n",
            "INFO:tensorflow:Not downloading, file already found: /root/t2t/tmp/t10k-images-idx3-ubyte.gz\n",
            "INFO:tensorflow:Not downloading, file already found: /root/t2t/tmp/t10k-labels-idx1-ubyte.gz\n",
            "INFO:tensorflow:Not downloading, file already found: /root/t2t/tmp/train-images-idx3-ubyte.gz\n",
            "INFO:tensorflow:Not downloading, file already found: /root/t2t/tmp/train-labels-idx1-ubyte.gz\n",
            "INFO:tensorflow:Not downloading, file already found: /root/t2t/tmp/t10k-images-idx3-ubyte.gz\n",
            "INFO:tensorflow:Not downloading, file already found: /root/t2t/tmp/t10k-labels-idx1-ubyte.gz\n",
            "INFO:tensorflow:Skipping generator because outputs files exists at ['/root/t2t/data/image_mnist-unshuffled-train-00000-of-00010', '/root/t2t/data/image_mnist-unshuffled-train-00001-of-00010', '/root/t2t/data/image_mnist-unshuffled-train-00002-of-00010', '/root/t2t/data/image_mnist-unshuffled-train-00003-of-00010', '/root/t2t/data/image_mnist-unshuffled-train-00004-of-00010', '/root/t2t/data/image_mnist-unshuffled-train-00005-of-00010', '/root/t2t/data/image_mnist-unshuffled-train-00006-of-00010', '/root/t2t/data/image_mnist-unshuffled-train-00007-of-00010', '/root/t2t/data/image_mnist-unshuffled-train-00008-of-00010', '/root/t2t/data/image_mnist-unshuffled-train-00009-of-00010']\n",
            "INFO:tensorflow:Skipping generator because outputs files exists at ['/root/t2t/data/image_mnist-unshuffled-dev-00000-of-00001']\n",
            "INFO:tensorflow:Skipping shuffle because output files exist\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VW6HCRANFPYV",
        "colab_type": "code",
        "outputId": "535fa6f2-ab68-425c-beaa-9e8678c951fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "cell_type": "code",
      "source": [
        "# Now let's see the training MNIST data as Tensors.\n",
        "mnist_data = mnist_problem.dataset(Modes.TRAIN, data_dir)\n",
        "mnist_example_tensors = mnist_data.make_one_shot_iterator().get_next()\n",
        "mnist_example = sess.run(mnist_example_tensors)\n",
        "image = mnist_example[\"inputs\"]\n",
        "label = mnist_example[\"targets\"]\n",
        "\n",
        "plt.imshow(image[:, :, 0].astype(np.float32), cmap=plt.get_cmap('gray'))\n",
        "print(\"Label: %d\" % label)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reading data files from /root/t2t/data/image_mnist-train*\n",
            "INFO:tensorflow:partition: 0 num_data_files: 10\n",
            ":::MLPv0.5.0 transformer 1541964125.124738455 (<ipython-input-26-55840b779871>:1) input_order\n",
            "Label: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f39a9beb6a0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "gXL7_bVH49Kl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Basic MNIST model."
      ]
    },
    {
      "metadata": {
        "id": "jQlCd98qijmO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# One-off all code together.\n",
        "\n",
        "# Data.\n",
        "BATCH_SIZE = 100\n",
        "data_batches = mnist_data.repeat().batch(BATCH_SIZE).make_one_shot_iterator()\n",
        "batch = data_batches.get_next()\n",
        "x, y = batch[\"inputs\"], batch[\"targets\"]\n",
        "x = tf.reshape(x, [BATCH_SIZE, 28*28])  # Height and width on channels.\n",
        "y = tf.squeeze(y, axis=1)  # Bogus dimension.\n",
        "# Model.\n",
        "hidden_size = 128\n",
        "h = tf.layers.dense(x, hidden_size, activation=tf.nn.relu, name=\"hidden\")\n",
        "o = tf.layers.dense(h, 10, activation=tf.nn.relu, name=\"output\")\n",
        "loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=o, labels=y)\n",
        "accuracy = tf.to_float(tf.equal(tf.argmax(o, axis=-1), y))\n",
        "loss_t, accuracy_t = tf.reduce_mean(loss), tf.reduce_mean(accuracy)\n",
        "# Gradients.\n",
        "train_op = tf.train.AdamOptimizer().minimize(loss_t)\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "37NrUjoulXJz",
        "colab_type": "code",
        "outputId": "579a3739-5d6b-45d3-8481-b072b41dd5bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "cell_type": "code",
      "source": [
        "# Train.\n",
        "num_steps = 1200  #  2 epochs on 60K examples.\n",
        "for step in range(num_steps):\n",
        "  _, loss, accuracy = sess.run([train_op, loss_t, accuracy_t])\n",
        "  if step % 100 == 0:\n",
        "    print(\"Step %d loss %.4f accuracy %.2f\" % (step, loss, accuracy))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 0 loss 2.5756 accuracy 0.07\n",
            "Step 100 loss 0.2459 accuracy 0.94\n",
            "Step 200 loss 0.2943 accuracy 0.92\n",
            "Step 300 loss 0.1252 accuracy 0.97\n",
            "Step 400 loss 0.2061 accuracy 0.95\n",
            "Step 500 loss 0.1120 accuracy 0.98\n",
            "Step 600 loss 0.1161 accuracy 0.98\n",
            "Step 700 loss 0.1714 accuracy 0.95\n",
            "Step 800 loss 0.0421 accuracy 0.98\n",
            "Step 900 loss 0.0635 accuracy 0.98\n",
            "Step 1000 loss 0.0903 accuracy 0.98\n",
            "Step 1100 loss 0.0365 accuracy 0.99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xilLpmrK6wMB",
        "colab_type": "code",
        "outputId": "d4a6c70c-13fb-4425-f798-572bb9bf0715",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "cell_type": "code",
      "source": [
        "# Once again, all refactored and with reset.\n",
        "\n",
        "# Reset.\n",
        "sess.close()\n",
        "tf.reset_default_graph()\n",
        "sess = tf.Session()\n",
        "\n",
        "# Data.\n",
        "problem = problems.problem(\"image_mnist\")\n",
        "problem.generate_data(data_dir, tmp_dir)\n",
        "BATCH_SIZE = 100\n",
        "train_data = problem.dataset(Modes.TRAIN, data_dir)\n",
        "train_batches = train_data.repeat().batch(BATCH_SIZE)\n",
        "train_batch = train_batches.make_one_shot_iterator().get_next()\n",
        "eval_data = problem.dataset(Modes.EVAL, data_dir)\n",
        "eval_batches = eval_data.repeat().batch(BATCH_SIZE)\n",
        "eval_batch = eval_batches.make_one_shot_iterator().get_next()\n",
        "\n",
        "# Model\n",
        "def model(batch, mode):\n",
        "  with tf.variable_scope(\"mymodel\", reuse=mode == Modes.EVAL):\n",
        "    # Inputs.\n",
        "    x, y = batch[\"inputs\"], batch[\"targets\"]\n",
        "    x = tf.reshape(x, [BATCH_SIZE, 28*28])  # Height and width on channels.\n",
        "    y = tf.squeeze(y, axis=1)  # Bogus dimension.\n",
        "    # Body.\n",
        "    hidden_size = 128\n",
        "    h = tf.layers.dense(x, hidden_size, activation=tf.nn.relu, name=\"hidden\")\n",
        "    o = tf.layers.dense(h, 10, activation=tf.nn.relu, name=\"output\")\n",
        "    # Loss and accuracy.\n",
        "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=o, labels=y)\n",
        "    accuracy = tf.to_float(tf.equal(tf.argmax(o, axis=-1), y))\n",
        "    return tf.reduce_mean(loss), tf.reduce_mean(accuracy)\n",
        "\n",
        "# Model for train.\n",
        "train_loss, train_accuracy = model(train_batch, Modes.TRAIN)\n",
        "# Gradients.\n",
        "train_op = tf.train.AdamOptimizer().minimize(train_loss)\n",
        "# Model for eval.\n",
        "eval_loss, eval_accuracy = model(eval_batch, Modes.EVAL)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Not downloading, file already found: /root/t2t/tmp/train-images-idx3-ubyte.gz\n",
            "INFO:tensorflow:Not downloading, file already found: /root/t2t/tmp/train-labels-idx1-ubyte.gz\n",
            "INFO:tensorflow:Not downloading, file already found: /root/t2t/tmp/t10k-images-idx3-ubyte.gz\n",
            "INFO:tensorflow:Not downloading, file already found: /root/t2t/tmp/t10k-labels-idx1-ubyte.gz\n",
            "INFO:tensorflow:Not downloading, file already found: /root/t2t/tmp/train-images-idx3-ubyte.gz\n",
            "INFO:tensorflow:Not downloading, file already found: /root/t2t/tmp/train-labels-idx1-ubyte.gz\n",
            "INFO:tensorflow:Not downloading, file already found: /root/t2t/tmp/t10k-images-idx3-ubyte.gz\n",
            "INFO:tensorflow:Not downloading, file already found: /root/t2t/tmp/t10k-labels-idx1-ubyte.gz\n",
            "INFO:tensorflow:Skipping generator because outputs files exists at ['/root/t2t/data/image_mnist-unshuffled-train-00000-of-00010', '/root/t2t/data/image_mnist-unshuffled-train-00001-of-00010', '/root/t2t/data/image_mnist-unshuffled-train-00002-of-00010', '/root/t2t/data/image_mnist-unshuffled-train-00003-of-00010', '/root/t2t/data/image_mnist-unshuffled-train-00004-of-00010', '/root/t2t/data/image_mnist-unshuffled-train-00005-of-00010', '/root/t2t/data/image_mnist-unshuffled-train-00006-of-00010', '/root/t2t/data/image_mnist-unshuffled-train-00007-of-00010', '/root/t2t/data/image_mnist-unshuffled-train-00008-of-00010', '/root/t2t/data/image_mnist-unshuffled-train-00009-of-00010']\n",
            "INFO:tensorflow:Skipping generator because outputs files exists at ['/root/t2t/data/image_mnist-unshuffled-dev-00000-of-00001']\n",
            "INFO:tensorflow:Skipping shuffle because output files exist\n",
            "INFO:tensorflow:Reading data files from /root/t2t/data/image_mnist-train*\n",
            "INFO:tensorflow:partition: 0 num_data_files: 10\n",
            ":::MLPv0.5.0 transformer 1541964146.334632397 (<ipython-input-29-2915dbeb35ed>:9) input_order\n",
            "INFO:tensorflow:Reading data files from /root/t2t/data/image_mnist-dev*\n",
            "INFO:tensorflow:partition: 0 num_data_files: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lYiY9Qz09ZUl",
        "colab_type": "code",
        "outputId": "dac7b996-9e73-4cee-b1c6-3f8bc998d070",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 892
        }
      },
      "cell_type": "code",
      "source": [
        "# Train.\n",
        "sess.run(tf.global_variables_initializer())\n",
        "num_steps = 2400  #  4 epochs on 60K examples.\n",
        "for step in range(num_steps + 1):\n",
        "  _, loss, accuracy = sess.run([train_op, train_loss, train_accuracy])\n",
        "  if step % 100 == 0:\n",
        "    print(\"Step %d train loss %.4f accuracy %.2f\" % (step, loss, accuracy))\n",
        "    loss, accuracy = sess.run([eval_loss, eval_accuracy])\n",
        "    print(\"Step %d eval loss %.4f accuracy %.2f\" % (step, loss, accuracy))\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 0 train loss 2.7247 accuracy 0.05\n",
            "Step 0 eval loss 2.4815 accuracy 0.13\n",
            "Step 100 train loss 0.1811 accuracy 0.92\n",
            "Step 100 eval loss 0.2622 accuracy 0.93\n",
            "Step 200 train loss 0.3427 accuracy 0.91\n",
            "Step 200 eval loss 0.2392 accuracy 0.94\n",
            "Step 300 train loss 0.1810 accuracy 0.94\n",
            "Step 300 eval loss 0.1942 accuracy 0.95\n",
            "Step 400 train loss 0.1553 accuracy 0.95\n",
            "Step 400 eval loss 0.2462 accuracy 0.92\n",
            "Step 500 train loss 0.1197 accuracy 0.96\n",
            "Step 500 eval loss 0.0966 accuracy 0.98\n",
            "Step 600 train loss 0.2403 accuracy 0.92\n",
            "Step 600 eval loss 0.0692 accuracy 0.99\n",
            "Step 700 train loss 0.3368 accuracy 0.93\n",
            "Step 700 eval loss 0.0501 accuracy 0.99\n",
            "Step 800 train loss 0.0791 accuracy 0.97\n",
            "Step 800 eval loss 0.0665 accuracy 0.99\n",
            "Step 900 train loss 0.1397 accuracy 0.94\n",
            "Step 900 eval loss 0.1421 accuracy 0.97\n",
            "Step 1000 train loss 0.0739 accuracy 0.96\n",
            "Step 1000 eval loss 0.2016 accuracy 0.94\n",
            "Step 1100 train loss 0.1279 accuracy 0.95\n",
            "Step 1100 eval loss 0.0561 accuracy 0.99\n",
            "Step 1200 train loss 0.1501 accuracy 0.97\n",
            "Step 1200 eval loss 0.0377 accuracy 0.99\n",
            "Step 1300 train loss 0.0565 accuracy 0.99\n",
            "Step 1300 eval loss 0.1496 accuracy 0.97\n",
            "Step 1400 train loss 0.1287 accuracy 0.96\n",
            "Step 1400 eval loss 0.0465 accuracy 0.99\n",
            "Step 1500 train loss 0.0669 accuracy 0.99\n",
            "Step 1500 eval loss 0.1355 accuracy 0.95\n",
            "Step 1600 train loss 0.0357 accuracy 0.99\n",
            "Step 1600 eval loss 0.0612 accuracy 0.98\n",
            "Step 1700 train loss 0.0158 accuracy 1.00\n",
            "Step 1700 eval loss 0.0423 accuracy 0.97\n",
            "Step 1800 train loss 0.0964 accuracy 0.95\n",
            "Step 1800 eval loss 0.0803 accuracy 0.98\n",
            "Step 1900 train loss 0.0742 accuracy 0.99\n",
            "Step 1900 eval loss 0.0293 accuracy 0.99\n",
            "Step 2000 train loss 0.0243 accuracy 0.99\n",
            "Step 2000 eval loss 0.0458 accuracy 0.99\n",
            "Step 2100 train loss 0.0340 accuracy 0.99\n",
            "Step 2100 eval loss 0.0220 accuracy 0.99\n",
            "Step 2200 train loss 0.0374 accuracy 0.99\n",
            "Step 2200 eval loss 0.1384 accuracy 0.98\n",
            "Step 2300 train loss 0.0294 accuracy 1.00\n",
            "Step 2300 eval loss 0.0409 accuracy 0.99\n",
            "Step 2400 train loss 0.0147 accuracy 1.00\n",
            "Step 2400 eval loss 0.1244 accuracy 0.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8XWHdOtcRO7W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Simple sequence models"
      ]
    },
    {
      "metadata": {
        "id": "vGbrR07mYFSh",
        "colab_type": "code",
        "outputId": "2cffbcc1-fb2a-47a4-81d2-0c13318477d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "def generator(l):\n",
        "  inputs = list(np.random.randint(2, size=l))\n",
        "  even = [x for i, x in enumerate(inputs) if i % 2 == 0]\n",
        "  repeated = [[x, x] for x in even]\n",
        "  targets = [z for p in repeated for z in p]\n",
        "  yield {\"inputs\": inputs, \"targets\": targets}\n",
        "\n",
        "generator1 = lambda: generator(10)\n",
        "generator2 = lambda: generator(20)\n",
        "\n",
        "print(six.next(generator(8)))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'inputs': [0, 0, 1, 0, 0, 0, 0, 1], 'targets': [0, 0, 1, 1, 0, 0, 0, 0]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cBhZ2-I1RXF5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Sequence model with 1 conv layer.\n",
        "\n",
        "# Reset.\n",
        "sess.close()\n",
        "tf.reset_default_graph()\n",
        "sess = tf.Session()\n",
        "\n",
        "# Data.\n",
        "types = {\"inputs\": tf.int64, \"targets\": tf.int64}\n",
        "shapes = {\"inputs\": tf.TensorShape([None]), \"targets\": tf.TensorShape([None])}\n",
        "\n",
        "train_data = tf.data.Dataset.from_generator(\n",
        "    generator2, output_types=types, output_shapes=shapes)\n",
        "eval_data = tf.data.Dataset.from_generator(\n",
        "    generator2, output_types=types, output_shapes=shapes)\n",
        "BATCH_SIZE = 100\n",
        "train_batches = train_data.repeat().batch(BATCH_SIZE)\n",
        "train_batch = train_batches.make_one_shot_iterator().get_next()\n",
        "eval_batches = eval_data.repeat().batch(BATCH_SIZE)\n",
        "eval_batch = eval_batches.make_one_shot_iterator().get_next()\n",
        "\n",
        "# Model\n",
        "def model(batch, mode):\n",
        "  with tf.variable_scope(\"mymodel\", reuse=mode == Modes.EVAL):\n",
        "    # Inputs.\n",
        "    x, y = batch[\"inputs\"], batch[\"targets\"]\n",
        "    x = tf.reshape(x, [BATCH_SIZE, -1, 1])\n",
        "    y = tf.reshape(y, [BATCH_SIZE, -1, 1])\n",
        "    x_hot = tf.one_hot(x, 2)  # From ints to 1-hot vectors.\n",
        "    y_hot = tf.one_hot(y, 2)\n",
        "    x = tf.layers.dense(x_hot, 32, name=\"embedding_x\")\n",
        "    y_emb = tf.layers.dense(y_hot, 32, name=\"embedding_y\")\n",
        "    # Exercise: try enabling the 2 lines below.\n",
        "    positions = tf.get_variable(\"positions\", [1, 20, 1, 32])\n",
        "    x += positions[:, :tf.shape(x)[1], :, :]\n",
        "    # Body.\n",
        "    hidden_size = 32\n",
        "    h = tf.layers.conv2d(x, hidden_size, (3, 1),\n",
        "                         padding=\"same\", activation=tf.nn.relu, name=\"hidden\")\n",
        "    o = tf.layers.conv2d(h, 2, (1, 1),\n",
        "                         padding=\"same\", name=\"output\")\n",
        "    # Loss and accuracy.\n",
        "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=o, labels=y)\n",
        "    accuracy = tf.to_float(tf.equal(tf.argmax(o, axis=-1), y))\n",
        "    return tf.reduce_mean(loss), tf.reduce_mean(accuracy)\n",
        "\n",
        "# Model for train.\n",
        "train_loss, train_accuracy = model(train_batch, Modes.TRAIN)\n",
        "# Gradients.\n",
        "train_op = tf.train.AdamOptimizer().minimize(train_loss)\n",
        "# Model for eval.\n",
        "eval_loss, eval_accuracy = model(eval_batch, Modes.EVAL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gXT8zEbpXaao",
        "colab_type": "code",
        "outputId": "edf4311c-056e-4e94-d486-35c82574bc9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        }
      },
      "cell_type": "code",
      "source": [
        "# Train.\n",
        "sess.run(tf.global_variables_initializer())\n",
        "num_steps = 200\n",
        "for step in range(num_steps + 1):\n",
        "  _, loss, accuracy = sess.run([train_op, train_loss, train_accuracy])\n",
        "  if step % 10 == 0:\n",
        "    print(\"Step %d train loss %.4f accuracy %.2f\" % (step, loss, accuracy))\n",
        "    loss, accuracy = sess.run([eval_loss, eval_accuracy])\n",
        "    print(\"Step %d eval loss %.4f accuracy %.2f\" % (step, loss, accuracy))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 0 train loss 0.6712 accuracy 0.55\n",
            "Step 0 eval loss 0.6614 accuracy 0.57\n",
            "Step 10 train loss 0.5411 accuracy 0.79\n",
            "Step 10 eval loss 0.5232 accuracy 0.80\n",
            "Step 20 train loss 0.4530 accuracy 0.77\n",
            "Step 20 eval loss 0.4389 accuracy 0.77\n",
            "Step 30 train loss 0.3878 accuracy 0.80\n",
            "Step 30 eval loss 0.3870 accuracy 0.80\n",
            "Step 40 train loss 0.3483 accuracy 0.83\n",
            "Step 40 eval loss 0.3505 accuracy 0.86\n",
            "Step 50 train loss 0.3260 accuracy 0.89\n",
            "Step 50 eval loss 0.3269 accuracy 0.89\n",
            "Step 60 train loss 0.3143 accuracy 0.95\n",
            "Step 60 eval loss 0.3165 accuracy 0.96\n",
            "Step 70 train loss 0.2861 accuracy 0.96\n",
            "Step 70 eval loss 0.2796 accuracy 0.97\n",
            "Step 80 train loss 0.2347 accuracy 1.00\n",
            "Step 80 eval loss 0.2369 accuracy 1.00\n",
            "Step 90 train loss 0.2047 accuracy 1.00\n",
            "Step 90 eval loss 0.1931 accuracy 1.00\n",
            "Step 100 train loss 0.1562 accuracy 1.00\n",
            "Step 100 eval loss 0.1573 accuracy 1.00\n",
            "Step 110 train loss 0.1135 accuracy 1.00\n",
            "Step 110 eval loss 0.1054 accuracy 1.00\n",
            "Step 120 train loss 0.0687 accuracy 1.00\n",
            "Step 120 eval loss 0.0665 accuracy 1.00\n",
            "Step 130 train loss 0.0454 accuracy 1.00\n",
            "Step 130 eval loss 0.0430 accuracy 1.00\n",
            "Step 140 train loss 0.0317 accuracy 1.00\n",
            "Step 140 eval loss 0.0298 accuracy 1.00\n",
            "Step 150 train loss 0.0209 accuracy 1.00\n",
            "Step 150 eval loss 0.0211 accuracy 1.00\n",
            "Step 160 train loss 0.0167 accuracy 1.00\n",
            "Step 160 eval loss 0.0155 accuracy 1.00\n",
            "Step 170 train loss 0.0121 accuracy 1.00\n",
            "Step 170 eval loss 0.0121 accuracy 1.00\n",
            "Step 180 train loss 0.0099 accuracy 1.00\n",
            "Step 180 eval loss 0.0098 accuracy 1.00\n",
            "Step 190 train loss 0.0082 accuracy 1.00\n",
            "Step 190 eval loss 0.0081 accuracy 1.00\n",
            "Step 200 train loss 0.0070 accuracy 1.00\n",
            "Step 200 eval loss 0.0069 accuracy 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jfLujWj4jZmc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Autoregressive sequence models"
      ]
    },
    {
      "metadata": {
        "id": "Ohk22OBUjiry",
        "colab_type": "code",
        "outputId": "b9f7c29d-fa2d-43ae-d816-77c0f8136adc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "def generator(l):\n",
        "  inputs = list(np.random.randint(2, size=l))\n",
        "  even = [x for i, x in enumerate(inputs) if i % 2 == 0]\n",
        "  repeated = [[x, x] for x in even]\n",
        "  targets1 = [z for p in repeated for z in p]\n",
        "  targets2 = inputs\n",
        "  targets = random.choice([targets1, targets2])\n",
        "  yield {\"inputs\": inputs, \"targets\": targets}\n",
        "\n",
        "generator1 = lambda: generator(10)\n",
        "generator2 = lambda: generator(20)\n",
        "\n",
        "print(six.next(generator(6)))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'inputs': [1, 0, 0, 0, 0, 1], 'targets': [1, 1, 0, 0, 0, 0]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZyBn6jzOjS0S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Sequence model with 1 conv layer.\n",
        "\n",
        "# Reset.\n",
        "sess.close()\n",
        "tf.reset_default_graph()\n",
        "sess = tf.Session()\n",
        "\n",
        "# Data.\n",
        "types = {\"inputs\": tf.int64, \"targets\": tf.int64}\n",
        "shapes = {\"inputs\": tf.TensorShape([None]), \"targets\": tf.TensorShape([None])}\n",
        "\n",
        "train_data = tf.data.Dataset.from_generator(\n",
        "    generator1, output_types=types, output_shapes=shapes)\n",
        "eval_data = tf.data.Dataset.from_generator(\n",
        "    generator2, output_types=types, output_shapes=shapes)\n",
        "BATCH_SIZE = 100\n",
        "train_batches = train_data.repeat().batch(BATCH_SIZE)\n",
        "train_batch = train_batches.make_one_shot_iterator().get_next()\n",
        "eval_batches = eval_data.repeat().batch(BATCH_SIZE)\n",
        "eval_batch = eval_batches.make_one_shot_iterator().get_next()\n",
        "\n",
        "# Model\n",
        "def model(batch, mode):\n",
        "  with tf.variable_scope(\"mymodel\", reuse=mode == Modes.EVAL):\n",
        "    # Inputs.\n",
        "    x, y = batch[\"inputs\"], batch[\"targets\"]\n",
        "    x = tf.reshape(x, [BATCH_SIZE, -1, 1])\n",
        "    y = tf.reshape(y, [BATCH_SIZE, -1, 1])\n",
        "    x_hot = tf.one_hot(x, 2)  # From ints to 1-hot vectors.\n",
        "    y_hot = tf.one_hot(y, 2)\n",
        "    x = tf.layers.dense(x_hot, 32, name=\"embedding_x\")\n",
        "    y_emb = tf.layers.dense(y_hot, 32, name=\"embedding_y\")\n",
        "    positions = tf.scan(lambda a, z: tf.layers.dense(a, 32),\n",
        "                        tf.transpose(x, [1, 0, 2, 3]))\n",
        "    positions = tf.transpose(positions, [1, 0, 2, 3])\n",
        "    x += positions\n",
        "    # Body.\n",
        "    hidden_size = 32\n",
        "    h = tf.layers.conv2d(x, hidden_size, (3, 1),\n",
        "                         padding=\"same\", activation=tf.nn.relu, name=\"hidden\")\n",
        "    # Autoregressive part.\n",
        "    y_shifted = common_layers.shift_right(y_emb)\n",
        "    h += y_shifted\n",
        "    # Attention.\n",
        "    h = tf.expand_dims(tf.squeeze(h, axis=2), axis=1)\n",
        "    q = tf.layers.dense(h, 32, name=\"q\")\n",
        "    k = tf.layers.dense(h, 32, name=\"k\")\n",
        "    v = tf.layers.dense(h, 32, name=\"v\")\n",
        "    bias = common_attention.attention_bias_lower_triangle(\n",
        "              common_layers.shape_list(h)[1])\n",
        "    h += common_attention.dot_product_attention(q, k, v, bias)\n",
        "    h = tf.reshape(h, tf.shape(x))\n",
        "    # Logits.\n",
        "    o = tf.layers.conv2d(h, 2, (1, 1),\n",
        "                         padding=\"same\", name=\"output\")\n",
        "    # Loss and accuracy.\n",
        "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=o, labels=y)\n",
        "    accuracy = tf.to_float(tf.equal(tf.argmax(o, axis=-1), y))\n",
        "    return tf.reduce_mean(loss), tf.reduce_mean(accuracy)\n",
        "\n",
        "# Model for train.\n",
        "train_loss, train_accuracy = model(train_batch, Modes.TRAIN)\n",
        "# Gradients.\n",
        "train_op = tf.train.AdamOptimizer().minimize(train_loss)\n",
        "# Model for eval.\n",
        "eval_loss, eval_accuracy = model(eval_batch, Modes.EVAL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CNhxmv4IZ4VU",
        "colab_type": "code",
        "outputId": "5312f7be-e26c-49b5-b7ae-e7bd47150140",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        }
      },
      "cell_type": "code",
      "source": [
        "# Train.\n",
        "sess.run(tf.global_variables_initializer())\n",
        "num_steps = 200\n",
        "for step in range(num_steps + 1):\n",
        "  _, loss, accuracy = sess.run([train_op, train_loss, train_accuracy])\n",
        "  if step % 10 == 0:\n",
        "    print(\"Step %d train loss %.4f accuracy %.2f\" % (step, loss, accuracy))\n",
        "    loss, accuracy = sess.run([eval_loss, eval_accuracy])\n",
        "    print(\"Step %d eval loss %.4f accuracy %.2f\" % (step, loss, accuracy))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 0 train loss 0.6622 accuracy 0.63\n",
            "Step 0 eval loss 0.6525 accuracy 0.62\n",
            "Step 10 train loss 0.4566 accuracy 0.77\n",
            "Step 10 eval loss 0.4730 accuracy 0.76\n",
            "Step 20 train loss 0.2775 accuracy 0.90\n",
            "Step 20 eval loss 0.3294 accuracy 0.86\n",
            "Step 30 train loss 0.2479 accuracy 0.87\n",
            "Step 30 eval loss 0.2958 accuracy 0.85\n",
            "Step 40 train loss 0.2371 accuracy 0.88\n",
            "Step 40 eval loss 0.2306 accuracy 0.90\n",
            "Step 50 train loss 0.1727 accuracy 0.92\n",
            "Step 50 eval loss 0.2082 accuracy 0.91\n",
            "Step 60 train loss 0.1419 accuracy 0.94\n",
            "Step 60 eval loss 0.1768 accuracy 0.92\n",
            "Step 70 train loss 0.0960 accuracy 0.96\n",
            "Step 70 eval loss 0.1323 accuracy 0.94\n",
            "Step 80 train loss 0.0674 accuracy 0.98\n",
            "Step 80 eval loss 0.0816 accuracy 0.97\n",
            "Step 90 train loss 0.0419 accuracy 0.99\n",
            "Step 90 eval loss 0.1599 accuracy 0.95\n",
            "Step 100 train loss 0.0278 accuracy 0.99\n",
            "Step 100 eval loss 0.0752 accuracy 0.98\n",
            "Step 110 train loss 0.0314 accuracy 0.99\n",
            "Step 110 eval loss 0.2141 accuracy 0.95\n",
            "Step 120 train loss 0.0269 accuracy 0.99\n",
            "Step 120 eval loss 0.0117 accuracy 1.00\n",
            "Step 130 train loss 0.0237 accuracy 0.99\n",
            "Step 130 eval loss 0.0521 accuracy 0.98\n",
            "Step 140 train loss 0.0169 accuracy 0.99\n",
            "Step 140 eval loss 0.0265 accuracy 0.99\n",
            "Step 150 train loss 0.0172 accuracy 0.99\n",
            "Step 150 eval loss 0.0232 accuracy 0.99\n",
            "Step 160 train loss 0.0302 accuracy 0.99\n",
            "Step 160 eval loss 0.0093 accuracy 1.00\n",
            "Step 170 train loss 0.0267 accuracy 0.99\n",
            "Step 170 eval loss 0.0066 accuracy 1.00\n",
            "Step 180 train loss 0.0225 accuracy 0.99\n",
            "Step 180 eval loss 0.0112 accuracy 1.00\n",
            "Step 190 train loss 0.0299 accuracy 0.99\n",
            "Step 190 eval loss 0.0414 accuracy 0.98\n",
            "Step 200 train loss 0.0152 accuracy 0.99\n",
            "Step 200 eval loss 0.0438 accuracy 0.99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TNC9fVcnibcH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Run pre-trained translation Transformer model."
      ]
    },
    {
      "metadata": {
        "id": "EB4MP7_y_SuQ",
        "colab_type": "code",
        "outputId": "25c64ea7-da1b-478e-fb0d-48fd409d6f38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "cell_type": "code",
      "source": [
        "# Reset.\n",
        "sess.close()\n",
        "tf.reset_default_graph()\n",
        "sess = tf.Session()\n",
        "\n",
        "# Fetch the problem\n",
        "# problems.available()\n",
        "ende_problem = problems.problem(\"translate_ende_wmt32k\")\n",
        "\n",
        "# Copy the vocab file locally so we can encode inputs and decode model outputs\n",
        "# All vocabs are stored on GCS\n",
        "vocab_name = \"vocab.translate_ende_wmt32k.32768.subwords\"\n",
        "vocab_file = os.path.join(gs_data_dir, vocab_name)\n",
        "!gsutil cp {vocab_file} {data_dir}\n",
        "!head -n 20 {data_dir}/{vocab_name}\n",
        "# Get the encoders from the problem\n",
        "encoders = ende_problem.feature_encoders(data_dir)\n",
        "\n",
        "# Setup helper functions for encoding and decoding\n",
        "def encode(input_str, output_str=None):\n",
        "  \"\"\"Input str to features dict, ready for inference\"\"\"\n",
        "  inputs = encoders[\"inputs\"].encode(input_str) + [1]  # add EOS id\n",
        "  batch_inputs = tf.reshape(tf.constant(inputs), [1, -1, 1])  # Make it 3D.\n",
        "  return {\"inputs\": batch_inputs}\n",
        "\n",
        "def decode(integers):\n",
        "  \"\"\"List of ints to str\"\"\"\n",
        "  integers = list(np.squeeze(integers))\n",
        "  if 1 in integers:\n",
        "    integers = integers[:integers.index(1)]\n",
        "  return encoders[\"inputs\"].decode(np.squeeze(integers))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://tensor2tensor-data/vocab.translate_ende_wmt32k.32768.subwords...\n",
            "/ [1 files][313.8 KiB/313.8 KiB]                                                \n",
            "Operation completed over 1 objects/313.8 KiB.                                    \n",
            "'<pad>_'\n",
            "'<EOS>_'\n",
            "', _'\n",
            "'._'\n",
            "'the_'\n",
            "'_'\n",
            "'in_'\n",
            "'of_'\n",
            "'and_'\n",
            "'to_'\n",
            "'die_'\n",
            "'der_'\n",
            "'und_'\n",
            "'a_'\n",
            "'s_'\n",
            "'-_'\n",
            "'is_'\n",
            "'that_'\n",
            "'zu_'\n",
            "'for_'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g2aQW7Z6TOEu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # Generate and view the data\n",
        "# # This cell is commented out because WMT data generation can take hours\n",
        "\n",
        "# ende_problem.generate_data(data_dir, tmp_dir)\n",
        "# example = tfe.Iterator(ende_problem.dataset(Modes.TRAIN, data_dir)).next()\n",
        "# inputs = [int(x) for x in example[\"inputs\"].numpy()] # Cast to ints.\n",
        "# targets = [int(x) for x in example[\"targets\"].numpy()] # Cast to ints.\n",
        "\n",
        "\n",
        "\n",
        "# # Example inputs as int-tensor.\n",
        "# print(\"Inputs, encoded:\")\n",
        "# print(inputs)\n",
        "# print(\"Inputs, decoded:\")\n",
        "# # Example inputs as a sentence.\n",
        "# print(decode(inputs))\n",
        "# # Example targets as int-tensor.\n",
        "# print(\"Targets, encoded:\")\n",
        "# print(targets)\n",
        "# # Example targets as a sentence.\n",
        "# print(\"Targets, decoded:\")\n",
        "# print(decode(targets))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9l6hDQbrRUYV",
        "colab_type": "code",
        "outputId": "eadfc18e-a9b4-4a14-8263-d9fbd53b45d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "# Create hparams and the model\n",
        "# registry.list_models()\n",
        "model_name = \"transformer\"\n",
        "hparams_set = \"transformer_base\"\n",
        "\n",
        "hparams = trainer_lib.create_hparams(hparams_set, data_dir=data_dir, problem_name=\"translate_ende_wmt32k\")\n",
        "\n",
        "# NOTE: Only create the model once when restoring from a checkpoint; it's a\n",
        "# Layer and so subsequent instantiations will have different variable scopes\n",
        "# that will not match the checkpoint.\n",
        "translate_model = registry.model(model_name)(hparams, Modes.EVAL)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
            "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
            "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FEwNUVlMYOJi",
        "colab_type": "code",
        "outputId": "53349571-05b1-483c-ccb2-07f27090164e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Copy the pretrained checkpoint locally\n",
        "ckpt_name = \"transformer_ende_test\"\n",
        "gs_ckpt = os.path.join(gs_ckpt_dir, ckpt_name)\n",
        "!gsutil -q cp -R {gs_ckpt} {checkpoint_dir}\n",
        "ckpt_path = tf.train.latest_checkpoint(os.path.join(checkpoint_dir, ckpt_name))\n",
        "ckpt_path"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/t2t/checkpoints/transformer_ende_test/model.ckpt-1421000'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "3O-8E9d6TtuJ",
        "colab_type": "code",
        "outputId": "e81d47de-1e2c-4554-f806-f4ba3e4c44ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2113
        }
      },
      "cell_type": "code",
      "source": [
        "# Restore and translate!\n",
        "def translate(inputs):\n",
        "  encoded_inputs = encode(inputs)\n",
        "  model_output = translate_model.infer(encoded_inputs)[\"outputs\"]\n",
        "  tf.train.Saver().restore(sess, ckpt_path)\n",
        "  return decode(sess.run(model_output))\n",
        "\n",
        "inputs = \"The animal didn't cross the street because it was too tired today.\"\n",
        "outputs = translate(inputs)\n",
        "\n",
        "print(\"Inputs: %s\" % inputs)\n",
        "print(\"Outputs: %s\" % outputs)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Greedy Decoding\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-ffc1a6f454b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"The animal didn't cross the street because it was too tired today.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Inputs: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-ffc1a6f454b4>\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mencoded_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"outputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/t2t_model.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, features, decode_length, beam_size, top_beams, alpha, use_tpu)\u001b[0m\n\u001b[1;32m    670\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbeam_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0mlog_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Greedy Decoding\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_greedy_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_tpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mlog_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Beam Decoding with beam size %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py\u001b[0m in \u001b[0;36m_greedy_infer\u001b[0;34m(self, features, decode_length, use_tpu)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m       return (self._fast_decode_tpu(features, decode_length) if use_tpu else\n\u001b[0;32m--> 244\u001b[0;31m               self._fast_decode(features, decode_length))\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m   def _beam_decode(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py\u001b[0m in \u001b[0;36m_fast_decode\u001b[0;34m(self, features, decode_length, beam_size, top_beams, alpha)\u001b[0m\n\u001b[1;32m    564\u001b[0m       \u001b[0minput_modality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_problem_hparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodality\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_modality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_modality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbottom_sharded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"body\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         encoder_output, encoder_decoder_attention_bias = dp(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/modality.py\u001b[0m in \u001b[0;36mbottom_sharded\u001b[0;34m(self, xs, data_parallelism)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_input_depth\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \"\"\"\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata_parallelism\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbottom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtargets_bottom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/expert_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_devices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mDEFAULT_DEV_STRING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_devices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m               \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmy_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmy_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmy_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmy_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/modalities.py\u001b[0m in \u001b[0;36mbottom\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    118\u001b[0m     if (self._model_hparams.shared_embedding_and_softmax_weights or\n\u001b[1;32m    119\u001b[0m         self._model_hparams.get(\"shared_embedding\")):\n\u001b[0;32m--> 120\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbottom_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shared\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbottom_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input_emb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/modalities.py\u001b[0m in \u001b[0;36mbottom_simple\u001b[0;34m(self, x, name, reuse)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m       x = common_layers.dropout_no_scaling(\n\u001b[1;32m    110\u001b[0m           x, 1.0 - self._model_hparams.symbol_dropout)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/modalities.py\u001b[0m in \u001b[0;36m_get_weights\u001b[0;34m(self, hidden_dim)\u001b[0m\n\u001b[1;32m     88\u001b[0m           tf.get_variable(\n\u001b[1;32m     89\u001b[0m               \u001b[0mvar_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mshard_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m               initializer=tf.random_normal_initializer(0.0, hidden_dim**-0.5)))\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_shards\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1485\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1487\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1235\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m   def _get_partitioned_variable(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    538\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m   def _get_partitioned_variable(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    490\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;31m# Set trainable value based on synchronization value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    859\u001b[0m                          \u001b[0;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[0;32m--> 861\u001b[0;31m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    862\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Variable transformer/symbol_modality_33288_512/shared/weights_0 already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/modalities.py\", line 90, in _get_weights\n    initializer=tf.random_normal_initializer(0.0, hidden_dim**-0.5)))\n  File \"/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/modalities.py\", line 108, in bottom_simple\n    var = self._get_weights()\n  File \"/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/modalities.py\", line 120, in bottom\n    return self.bottom_simple(x, \"shared\", reuse=None)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "WIKgSZaaYrpT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train Transformer on Translation "
      ]
    },
    {
      "metadata": {
        "id": "GJVscCdTZrAv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 15591
        },
        "outputId": "d1452150-8cf5-45cc-e1a2-d767d592135e"
      },
      "cell_type": "code",
      "source": [
        "!t2t-trainer  --generate_data \\\n",
        "  --data_dir=~/t2t_data \\\n",
        "  --output_dir=~/t2t_train/translate \\\n",
        "  --problem=translate_enfr_wmt_small32k \\\n",
        "  --model=transformer \\\n",
        "  --hparams_set=transformer_small \\\n",
        "  --train_steps=15000 \\\n",
        "  --eval_steps=10 \\\n",
        "  --hparams=\"summarize_vars=1\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ":::MLPv0.5.0 transformer 1541965368.861434698 (/usr/local/bin/t2t-trainer:28) run_start\n",
            ":::MLPv0.5.0 transformer 1541965368.862154245 (/usr/local/bin/t2t-trainer:28) run_set_random_seed\n",
            "INFO:tensorflow:Generating data for translate_enfr_wmt_small32k\n",
            "INFO:tensorflow:Skipping compile data, found files:\n",
            "/tmp/t2t_datagen/translate_enfr_wmt_small32k-compiled-train.lang1\n",
            "/tmp/t2t_datagen/translate_enfr_wmt_small32k-compiled-train.lang2\n",
            "INFO:tensorflow:Generating vocab file: /root/t2t_data/vocab.translate_enfr_wmt_small32k.32768.subwords\n",
            "INFO:tensorflow:Generating vocab from: [['https://s3.amazonaws.com/opennmt-trainingdata/baseline-1M-enfr.tgz', ('baseline-1M-enfr/baseline-1M_train.en', 'baseline-1M-enfr/baseline-1M_train.fr')]]\n",
            "INFO:tensorflow:Not downloading, file already found: /tmp/t2t_datagen/baseline-1M-enfr.tgz\n",
            "INFO:tensorflow:Reading file: baseline-1M-enfr/baseline-1M_train.en\n",
            "INFO:tensorflow:Reading file: baseline-1M-enfr/baseline-1M_train.fr\n",
            "INFO:tensorflow:Trying min_count 500\n",
            "INFO:tensorflow:Iteration 0\n",
            "INFO:tensorflow:vocab_size = 1182\n",
            "INFO:tensorflow:Iteration 1\n",
            "INFO:tensorflow:vocab_size = 656\n",
            "INFO:tensorflow:Iteration 2\n",
            "INFO:tensorflow:vocab_size = 714\n",
            "INFO:tensorflow:Iteration 3\n",
            "INFO:tensorflow:vocab_size = 690\n",
            "INFO:tensorflow:Trying min_count 250\n",
            "INFO:tensorflow:Iteration 0\n",
            "INFO:tensorflow:vocab_size = 2089\n",
            "INFO:tensorflow:Iteration 1\n",
            "INFO:tensorflow:vocab_size = 1049\n",
            "INFO:tensorflow:Iteration 2\n",
            "INFO:tensorflow:vocab_size = 1122\n",
            "INFO:tensorflow:Iteration 3\n",
            "INFO:tensorflow:vocab_size = 1104\n",
            "INFO:tensorflow:Trying min_count 125\n",
            "INFO:tensorflow:Iteration 0\n",
            "INFO:tensorflow:vocab_size = 3792\n",
            "INFO:tensorflow:Iteration 1\n",
            "INFO:tensorflow:vocab_size = 1703\n",
            "INFO:tensorflow:Iteration 2\n",
            "INFO:tensorflow:vocab_size = 1800\n",
            "INFO:tensorflow:Iteration 3\n",
            "INFO:tensorflow:vocab_size = 1780\n",
            "INFO:tensorflow:Trying min_count 62\n",
            "INFO:tensorflow:Iteration 0\n",
            "INFO:tensorflow:vocab_size = 6762\n",
            "INFO:tensorflow:Iteration 1\n",
            "INFO:tensorflow:vocab_size = 2744\n",
            "INFO:tensorflow:Iteration 2\n",
            "INFO:tensorflow:vocab_size = 2873\n",
            "INFO:tensorflow:Iteration 3\n",
            "INFO:tensorflow:vocab_size = 2853\n",
            "INFO:tensorflow:Trying min_count 31\n",
            "INFO:tensorflow:Iteration 0\n",
            "INFO:tensorflow:vocab_size = 11324\n",
            "INFO:tensorflow:Iteration 1\n",
            "INFO:tensorflow:vocab_size = 4288\n",
            "INFO:tensorflow:Iteration 2\n",
            "INFO:tensorflow:vocab_size = 4450\n",
            "INFO:tensorflow:Iteration 3\n",
            "INFO:tensorflow:vocab_size = 4422\n",
            "INFO:tensorflow:Trying min_count 15\n",
            "INFO:tensorflow:Iteration 0\n",
            "INFO:tensorflow:vocab_size = 18677\n",
            "INFO:tensorflow:Iteration 1\n",
            "INFO:tensorflow:vocab_size = 6854\n",
            "INFO:tensorflow:Iteration 2\n",
            "INFO:tensorflow:vocab_size = 7051\n",
            "INFO:tensorflow:Iteration 3\n",
            "INFO:tensorflow:vocab_size = 7019\n",
            "INFO:tensorflow:Trying min_count 7\n",
            "INFO:tensorflow:Iteration 0\n",
            "INFO:tensorflow:vocab_size = 30239\n",
            "INFO:tensorflow:Iteration 1\n",
            "INFO:tensorflow:vocab_size = 10840\n",
            "INFO:tensorflow:Iteration 2\n",
            "INFO:tensorflow:vocab_size = 11076\n",
            "INFO:tensorflow:Iteration 3\n",
            "INFO:tensorflow:vocab_size = 11068\n",
            "INFO:tensorflow:Trying min_count 3\n",
            "INFO:tensorflow:Iteration 0\n",
            "INFO:tensorflow:vocab_size = 49810\n",
            "INFO:tensorflow:Iteration 1\n",
            "INFO:tensorflow:vocab_size = 17668\n",
            "INFO:tensorflow:Iteration 2\n",
            "INFO:tensorflow:vocab_size = 18002\n",
            "INFO:tensorflow:Iteration 3\n",
            "INFO:tensorflow:vocab_size = 17929\n",
            "INFO:tensorflow:Trying min_count 1\n",
            "INFO:tensorflow:Iteration 0\n",
            "INFO:tensorflow:vocab_size = 85800\n",
            "INFO:tensorflow:Iteration 1\n",
            "INFO:tensorflow:vocab_size = 27927\n",
            "INFO:tensorflow:Iteration 2\n",
            "INFO:tensorflow:vocab_size = 27927\n",
            "INFO:tensorflow:Iteration 3\n",
            "INFO:tensorflow:vocab_size = 27927\n",
            "INFO:tensorflow:Generating case 0.\n",
            "INFO:tensorflow:Generating case 100000.\n",
            "INFO:tensorflow:Generating case 200000.\n",
            "INFO:tensorflow:Generating case 300000.\n",
            "INFO:tensorflow:Generating case 400000.\n",
            "INFO:tensorflow:Generated 438743 Examples\n",
            "INFO:tensorflow:Not downloading, file already found: /tmp/t2t_datagen/baseline-1M-enfr.tgz\n",
            "INFO:tensorflow:Found vocab file: /root/t2t_data/vocab.translate_enfr_wmt_small32k.32768.subwords\n",
            "INFO:tensorflow:Generating case 0.\n",
            "INFO:tensorflow:Generated 1000 Examples\n",
            "INFO:tensorflow:Shuffling data...\n",
            "INFO:tensorflow:Data shuffled.\n",
            "INFO:tensorflow:Overriding hparams in transformer_small with summarize_vars=1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/trainer_lib.py:230: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
            "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
            "INFO:tensorflow:schedule=continuous_train_and_eval\n",
            "INFO:tensorflow:worker_gpu=1\n",
            "INFO:tensorflow:sync=False\n",
            "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
            "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
            "INFO:tensorflow:caching_devices: None\n",
            "INFO:tensorflow:ps_devices: ['gpu:0']\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f78dee91198>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': None, '_log_step_count_steps': 100, '_protocol': None, '_session_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 0.95\n",
            "}\n",
            "allow_soft_placement: true\n",
            "graph_options {\n",
            "  optimizer_options {\n",
            "  }\n",
            "}\n",
            ", '_save_checkpoints_steps': 1000, '_keep_checkpoint_max': 20, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/root/t2t_train/translate', 'use_tpu': False, 't2t_device_info': {'num_async_replicas': 1}, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f78dee91208>}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f78e0b89a60>) includes params argument, but params are not passed to Estimator.\n",
            "WARNING:tensorflow:ValidationMonitor only works with --schedule=train_and_evaluate\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n",
            "INFO:tensorflow:Reading data files from /root/t2t_data/translate_enfr_wmt_small32k-train*\n",
            "INFO:tensorflow:partition: 0 num_data_files: 100\n",
            ":::MLPv0.5.0 transformer 1541965480.549999475 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/data_generators/problem.py:869) input_order\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensor2tensor/data_generators/problem.py:653: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensor2tensor/data_generators/problem.py:944: bucket_by_sequence_length (from tensorflow.contrib.data.python.ops.grouping) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.bucket_by_sequence_length(...)`.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
            ":::MLPv0.5.0 transformer 1541965484.107151985 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/t2t_model.py:213) model_hp_initializer_gain: 1.0\n",
            "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
            "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_27927_256.bottom\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/function.py:987: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
            "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_27927_256.targets_bottom\n",
            "INFO:tensorflow:Building model body\n",
            ":::MLPv0.5.0 transformer 1541965484.446801901 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.1\n",
            ":::MLPv0.5.0 transformer 1541965484.456258774 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
            ":::MLPv0.5.0 transformer 1541965484.457626820 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_num_heads: 4\n",
            ":::MLPv0.5.0 transformer 1541965484.459014893 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.1\n",
            ":::MLPv0.5.0 transformer 1541965484.867802620 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_ffn_filter: {\"filter_size\": 1024, \"use_bias\": \"True\", \"activation\": \"relu\"}\n",
            ":::MLPv0.5.0 transformer 1541965484.869297981 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_ffn_dense: {\"hidden_size\": 256, \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1541965484.870536566 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_relu_dropout: 0.1\n",
            ":::MLPv0.5.0 transformer 1541965485.248001575 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_ffn_filter: {\"filter_size\": 1024, \"use_bias\": \"True\", \"activation\": \"relu\"}\n",
            ":::MLPv0.5.0 transformer 1541965485.249387264 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_ffn_dense: {\"hidden_size\": 256, \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1541965485.250721455 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_relu_dropout: 0.1\n",
            ":::MLPv0.5.0 transformer 1541965485.365494251 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 256}\n",
            ":::MLPv0.5.0 transformer 1541965485.478083611 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.1\n",
            ":::MLPv0.5.0 transformer 1541965485.487833023 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
            ":::MLPv0.5.0 transformer 1541965485.489497185 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_num_heads: 4\n",
            ":::MLPv0.5.0 transformer 1541965485.490956068 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.1\n",
            ":::MLPv0.5.0 transformer 1541965485.990117311 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:1290) model_hp_ffn_filter: {\"filter_size\": 1024, \"use_bias\": \"True\", \"activation\": \"relu\"}\n",
            ":::MLPv0.5.0 transformer 1541965485.991466761 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:1290) model_hp_ffn_dense: {\"hidden_size\": 256, \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1541965485.992753744 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:1290) model_hp_relu_dropout: 0.1\n",
            ":::MLPv0.5.0 transformer 1541965486.760851383 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:1290) model_hp_ffn_filter: {\"filter_size\": 1024, \"use_bias\": \"True\", \"activation\": \"relu\"}\n",
            ":::MLPv0.5.0 transformer 1541965486.762437820 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:1290) model_hp_ffn_dense: {\"hidden_size\": 256, \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1541965486.763973713 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:1290) model_hp_relu_dropout: 0.1\n",
            ":::MLPv0.5.0 transformer 1541965486.863642216 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 256}\n",
            "INFO:tensorflow:Transforming body output with symbol_modality_27927_256.top\n",
            "INFO:tensorflow:Base learning rate: 2.000000\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_0/encdec_attention/layer_prepostprocess/layer_norm/layer_norm_bias\tshape    (256,)              \tsize    256\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_0/encdec_attention/layer_prepostprocess/layer_norm/layer_norm_scale\tshape    (256,)              \tsize    256\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_0/encdec_attention/multihead_attention/k/kernel  \tshape    (256, 256)          \tsize    65536\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_0/encdec_attention/multihead_attention/output_transform/kernel\tshape    (256, 256)          \tsize    65536\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_0/encdec_attention/multihead_attention/q/kernel  \tshape    (256, 256)          \tsize    65536\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_0/encdec_attention/multihead_attention/v/kernel  \tshape    (256, 256)          \tsize    65536\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_0/ffn/conv1/bias                                 \tshape    (1024,)             \tsize    1024\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_0/ffn/conv1/kernel                               \tshape    (256, 1024)         \tsize    262144\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_0/ffn/conv2/bias                                 \tshape    (256,)              \tsize    256\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_0/ffn/conv2/kernel                               \tshape    (1024, 256)         \tsize    262144\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_0/ffn/layer_prepostprocess/layer_norm/layer_norm_bias\tshape    (256,)              \tsize    256\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_0/ffn/layer_prepostprocess/layer_norm/layer_norm_scale\tshape    (256,)              \tsize    256\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_0/self_attention/layer_prepostprocess/layer_norm/layer_norm_bias\tshape    (256,)              \tsize    256\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_0/self_attention/layer_prepostprocess/layer_norm/layer_norm_scale\tshape    (256,)              \tsize    256\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_0/self_attention/multihead_attention/k/kernel    \tshape    (256, 256)          \tsize    65536\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_0/self_attention/multihead_attention/output_transform/kernel\tshape    (256, 256)          \tsize    65536\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_0/self_attention/multihead_attention/q/kernel    \tshape    (256, 256)          \tsize    65536\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_0/self_attention/multihead_attention/v/kernel    \tshape    (256, 256)          \tsize    65536\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_1/encdec_attention/layer_prepostprocess/layer_norm/layer_norm_bias\tshape    (256,)              \tsize    256\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_1/encdec_attention/layer_prepostprocess/layer_norm/layer_norm_scale\tshape    (256,)              \tsize    256\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_1/encdec_attention/multihead_attention/k/kernel  \tshape    (256, 256)          \tsize    65536\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_1/encdec_attention/multihead_attention/output_transform/kernel\tshape    (256, 256)          \tsize    65536\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_1/encdec_attention/multihead_attention/q/kernel  \tshape    (256, 256)          \tsize    65536\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_1/encdec_attention/multihead_attention/v/kernel  \tshape    (256, 256)          \tsize    65536\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_1/ffn/conv1/bias                                 \tshape    (1024,)             \tsize    1024\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_1/ffn/conv1/kernel                               \tshape    (256, 1024)         \tsize    262144\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_1/ffn/conv2/bias                                 \tshape    (256,)              \tsize    256\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_1/ffn/conv2/kernel                               \tshape    (1024, 256)         \tsize    262144\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_1/ffn/layer_prepostprocess/layer_norm/layer_norm_bias\tshape    (256,)              \tsize    256\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_1/ffn/layer_prepostprocess/layer_norm/layer_norm_scale\tshape    (256,)              \tsize    256\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_1/self_attention/layer_prepostprocess/layer_norm/layer_norm_bias\tshape    (256,)              \tsize    256\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_1/self_attention/layer_prepostprocess/layer_norm/layer_norm_scale\tshape    (256,)              \tsize    256\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_1/self_attention/multihead_attention/k/kernel    \tshape    (256, 256)          \tsize    65536\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_1/self_attention/multihead_attention/output_transform/kernel\tshape    (256, 256)          \tsize    65536\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_1/self_attention/multihead_attention/q/kernel    \tshape    (256, 256)          \tsize    65536\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_1/self_attention/multihead_attention/v/kernel    \tshape    (256, 256)          \tsize    65536\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_prepostprocess/layer_norm/layer_norm_bias        \tshape    (256,)              \tsize    256\n",
            "INFO:tensorflow:Weight    transformer/body/decoder/layer_prepostprocess/layer_norm/layer_norm_scale       \tshape    (256,)              \tsize    256\n",
            "INFO:tensorflow:Weight    transformer/body/encoder/layer_0/ffn/conv1/bias                                 \tshape    (1024,)             \tsize    1024\n",
            "INFO:tensorflow:Weight    transformer/body/encoder/layer_0/ffn/conv1/kernel                               \tshape    (256, 1024)         \tsize    262144\n",
            "INFO:tensorflow:Weight    transformer/body/encoder/layer_0/ffn/conv2/bias                                 \tshape    (256,)              \tsize    256\n",
            "INFO:tensorflow:Weight    transformer/body/encoder/layer_0/ffn/conv2/kernel                               \tshape    (1024, 256)         \tsize    262144\n",
            "INFO:tensorflow:Weight    transformer/body/encoder/layer_0/ffn/layer_prepostprocess/layer_norm/layer_norm_bias\tshape    (256,)              \tsize    256\n",
            "INFO:tensorflow:Weight    transformer/body/encoder/layer_0/ffn/layer_prepostprocess/layer_norm/layer_norm_scale\tshape    (256,)              \tsize    256\n",
            "INFO:tensorflow:Weight    transformer/body/encoder/layer_0/self_attention/layer_prepostprocess/layer_norm/layer_norm_bias\tshape    (256,)              \tsize    256\n",
            "INFO:tensorflow:Weight    transformer/body/encoder/layer_0/self_attention/layer_prepostprocess/layer_norm/layer_norm_scale\tshape    (256,)              \tsize    256\n",
            "INFO:tensorflow:Weight    transformer/body/encoder/layer_0/self_attention/multihead_attention/k/kernel    \tshape    (256, 256)          \tsize    65536\n",
            "INFO:tensorflow:Weight    transformer/body/encoder/layer_0/self_attention/multihead_attention/output_transform/kernel\tshape    (256, 256)          \tsize    65536\n",
            "INFO:tensorflow:Weight    transformer/body/encoder/layer_0/self_attention/multihead_attention/q/kernel    \tshape    (256, 256)          \tsize    65536\n",
            "INFO:tensorflow:Weight    transformer/body/encoder/layer_0/self_attention/multihead_attention/v/kernel    \tshape    (256, 256)          \tsize    65536\n",
            "INFO:tensorflow:Weight    transformer/body/encoder/layer_1/ffn/conv1/bias                                 \tshape    (1024,)             \tsize    1024\n",
            "INFO:tensorflow:Weight    transformer/body/encoder/layer_1/ffn/conv1/kernel                               \tshape    (256, 1024)         \tsize    262144\n",
            "INFO:tensorflow:Weight    transformer/body/encoder/layer_1/ffn/conv2/bias                                 \tshape    (256,)              \tsize    256\n",
            "INFO:tensorflow:Weight    transformer/body/encoder/layer_1/ffn/conv2/kernel                               \tshape    (1024, 256)         \tsize    262144\n",
            "INFO:tensorflow:Weight    transformer/body/encoder/layer_1/ffn/layer_prepostprocess/layer_norm/layer_norm_bias\tshape    (256,)              \tsize    256\n",
            "INFO:tensorflow:Weight    transformer/body/encoder/layer_1/ffn/layer_prepostprocess/layer_norm/layer_norm_scale\tshape    (256,)              \tsize    256\n",
            "INFO:tensorflow:Weight    transformer/body/encoder/layer_1/self_attention/layer_prepostprocess/layer_norm/layer_norm_bias\tshape    (256,)              \tsize    256\n",
            "INFO:tensorflow:Weight    transformer/body/encoder/layer_1/self_attention/layer_prepostprocess/layer_norm/layer_norm_scale\tshape    (256,)              \tsize    256\n",
            "INFO:tensorflow:Weight    transformer/body/encoder/layer_1/self_attention/multihead_attention/k/kernel    \tshape    (256, 256)          \tsize    65536\n",
            "INFO:tensorflow:Weight    transformer/body/encoder/layer_1/self_attention/multihead_attention/output_transform/kernel\tshape    (256, 256)          \tsize    65536\n",
            "INFO:tensorflow:Weight    transformer/body/encoder/layer_1/self_attention/multihead_attention/q/kernel    \tshape    (256, 256)          \tsize    65536\n",
            "INFO:tensorflow:Weight    transformer/body/encoder/layer_1/self_attention/multihead_attention/v/kernel    \tshape    (256, 256)          \tsize    65536\n",
            "INFO:tensorflow:Weight    transformer/body/encoder/layer_prepostprocess/layer_norm/layer_norm_bias        \tshape    (256,)              \tsize    256\n",
            "INFO:tensorflow:Weight    transformer/body/encoder/layer_prepostprocess/layer_norm/layer_norm_scale       \tshape    (256,)              \tsize    256\n",
            "INFO:tensorflow:Weight    transformer/body/target_space_embedding/kernel                                  \tshape    (32, 256)           \tsize    8192\n",
            "INFO:tensorflow:Weight    transformer/symbol_modality_27927_256/shared/weights_0                          \tshape    (1746, 256)         \tsize    446976\n",
            "INFO:tensorflow:Weight    transformer/symbol_modality_27927_256/shared/weights_10                         \tshape    (1745, 256)         \tsize    446720\n",
            "INFO:tensorflow:Weight    transformer/symbol_modality_27927_256/shared/weights_11                         \tshape    (1745, 256)         \tsize    446720\n",
            "INFO:tensorflow:Weight    transformer/symbol_modality_27927_256/shared/weights_12                         \tshape    (1745, 256)         \tsize    446720\n",
            "INFO:tensorflow:Weight    transformer/symbol_modality_27927_256/shared/weights_13                         \tshape    (1745, 256)         \tsize    446720\n",
            "INFO:tensorflow:Weight    transformer/symbol_modality_27927_256/shared/weights_14                         \tshape    (1745, 256)         \tsize    446720\n",
            "INFO:tensorflow:Weight    transformer/symbol_modality_27927_256/shared/weights_15                         \tshape    (1745, 256)         \tsize    446720\n",
            "INFO:tensorflow:Weight    transformer/symbol_modality_27927_256/shared/weights_1                          \tshape    (1746, 256)         \tsize    446976\n",
            "INFO:tensorflow:Weight    transformer/symbol_modality_27927_256/shared/weights_2                          \tshape    (1746, 256)         \tsize    446976\n",
            "INFO:tensorflow:Weight    transformer/symbol_modality_27927_256/shared/weights_3                          \tshape    (1746, 256)         \tsize    446976\n",
            "INFO:tensorflow:Weight    transformer/symbol_modality_27927_256/shared/weights_4                          \tshape    (1746, 256)         \tsize    446976\n",
            "INFO:tensorflow:Weight    transformer/symbol_modality_27927_256/shared/weights_5                          \tshape    (1746, 256)         \tsize    446976\n",
            "INFO:tensorflow:Weight    transformer/symbol_modality_27927_256/shared/weights_6                          \tshape    (1746, 256)         \tsize    446976\n",
            "INFO:tensorflow:Weight    transformer/symbol_modality_27927_256/shared/weights_7                          \tshape    (1745, 256)         \tsize    446720\n",
            "INFO:tensorflow:Weight    transformer/symbol_modality_27927_256/shared/weights_8                          \tshape    (1745, 256)         \tsize    446720\n",
            "INFO:tensorflow:Weight    transformer/symbol_modality_27927_256/shared/weights_9                          \tshape    (1745, 256)         \tsize    446720\n",
            "INFO:tensorflow:Trainable Variables Total size: 10838784\n",
            "INFO:tensorflow:Summary name training_variables/transformer/symbol_modality_27927_256/shared/weights_0:0 is illegal; using training_variables/transformer/symbol_modality_27927_256/shared/weights_0_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/symbol_modality_27927_256/shared/weights_1:0 is illegal; using training_variables/transformer/symbol_modality_27927_256/shared/weights_1_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/symbol_modality_27927_256/shared/weights_2:0 is illegal; using training_variables/transformer/symbol_modality_27927_256/shared/weights_2_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/symbol_modality_27927_256/shared/weights_3:0 is illegal; using training_variables/transformer/symbol_modality_27927_256/shared/weights_3_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/symbol_modality_27927_256/shared/weights_4:0 is illegal; using training_variables/transformer/symbol_modality_27927_256/shared/weights_4_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/symbol_modality_27927_256/shared/weights_5:0 is illegal; using training_variables/transformer/symbol_modality_27927_256/shared/weights_5_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/symbol_modality_27927_256/shared/weights_6:0 is illegal; using training_variables/transformer/symbol_modality_27927_256/shared/weights_6_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/symbol_modality_27927_256/shared/weights_7:0 is illegal; using training_variables/transformer/symbol_modality_27927_256/shared/weights_7_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/symbol_modality_27927_256/shared/weights_8:0 is illegal; using training_variables/transformer/symbol_modality_27927_256/shared/weights_8_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/symbol_modality_27927_256/shared/weights_9:0 is illegal; using training_variables/transformer/symbol_modality_27927_256/shared/weights_9_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/symbol_modality_27927_256/shared/weights_10:0 is illegal; using training_variables/transformer/symbol_modality_27927_256/shared/weights_10_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/symbol_modality_27927_256/shared/weights_11:0 is illegal; using training_variables/transformer/symbol_modality_27927_256/shared/weights_11_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/symbol_modality_27927_256/shared/weights_12:0 is illegal; using training_variables/transformer/symbol_modality_27927_256/shared/weights_12_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/symbol_modality_27927_256/shared/weights_13:0 is illegal; using training_variables/transformer/symbol_modality_27927_256/shared/weights_13_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/symbol_modality_27927_256/shared/weights_14:0 is illegal; using training_variables/transformer/symbol_modality_27927_256/shared/weights_14_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/symbol_modality_27927_256/shared/weights_15:0 is illegal; using training_variables/transformer/symbol_modality_27927_256/shared/weights_15_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/target_space_embedding/kernel:0 is illegal; using training_variables/transformer/body/target_space_embedding/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/encoder/layer_0/self_attention/layer_prepostprocess/layer_norm/layer_norm_scale:0 is illegal; using training_variables/transformer/body/encoder/layer_0/self_attention/layer_prepostprocess/layer_norm/layer_norm_scale_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/encoder/layer_0/self_attention/layer_prepostprocess/layer_norm/layer_norm_bias:0 is illegal; using training_variables/transformer/body/encoder/layer_0/self_attention/layer_prepostprocess/layer_norm/layer_norm_bias_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/encoder/layer_0/self_attention/multihead_attention/q/kernel:0 is illegal; using training_variables/transformer/body/encoder/layer_0/self_attention/multihead_attention/q/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/encoder/layer_0/self_attention/multihead_attention/k/kernel:0 is illegal; using training_variables/transformer/body/encoder/layer_0/self_attention/multihead_attention/k/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/encoder/layer_0/self_attention/multihead_attention/v/kernel:0 is illegal; using training_variables/transformer/body/encoder/layer_0/self_attention/multihead_attention/v/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/encoder/layer_0/self_attention/multihead_attention/output_transform/kernel:0 is illegal; using training_variables/transformer/body/encoder/layer_0/self_attention/multihead_attention/output_transform/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/encoder/layer_0/ffn/layer_prepostprocess/layer_norm/layer_norm_scale:0 is illegal; using training_variables/transformer/body/encoder/layer_0/ffn/layer_prepostprocess/layer_norm/layer_norm_scale_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/encoder/layer_0/ffn/layer_prepostprocess/layer_norm/layer_norm_bias:0 is illegal; using training_variables/transformer/body/encoder/layer_0/ffn/layer_prepostprocess/layer_norm/layer_norm_bias_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/encoder/layer_0/ffn/conv1/kernel:0 is illegal; using training_variables/transformer/body/encoder/layer_0/ffn/conv1/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/encoder/layer_0/ffn/conv1/bias:0 is illegal; using training_variables/transformer/body/encoder/layer_0/ffn/conv1/bias_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/encoder/layer_0/ffn/conv2/kernel:0 is illegal; using training_variables/transformer/body/encoder/layer_0/ffn/conv2/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/encoder/layer_0/ffn/conv2/bias:0 is illegal; using training_variables/transformer/body/encoder/layer_0/ffn/conv2/bias_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/encoder/layer_1/self_attention/layer_prepostprocess/layer_norm/layer_norm_scale:0 is illegal; using training_variables/transformer/body/encoder/layer_1/self_attention/layer_prepostprocess/layer_norm/layer_norm_scale_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/encoder/layer_1/self_attention/layer_prepostprocess/layer_norm/layer_norm_bias:0 is illegal; using training_variables/transformer/body/encoder/layer_1/self_attention/layer_prepostprocess/layer_norm/layer_norm_bias_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/encoder/layer_1/self_attention/multihead_attention/q/kernel:0 is illegal; using training_variables/transformer/body/encoder/layer_1/self_attention/multihead_attention/q/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/encoder/layer_1/self_attention/multihead_attention/k/kernel:0 is illegal; using training_variables/transformer/body/encoder/layer_1/self_attention/multihead_attention/k/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/encoder/layer_1/self_attention/multihead_attention/v/kernel:0 is illegal; using training_variables/transformer/body/encoder/layer_1/self_attention/multihead_attention/v/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/encoder/layer_1/self_attention/multihead_attention/output_transform/kernel:0 is illegal; using training_variables/transformer/body/encoder/layer_1/self_attention/multihead_attention/output_transform/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/encoder/layer_1/ffn/layer_prepostprocess/layer_norm/layer_norm_scale:0 is illegal; using training_variables/transformer/body/encoder/layer_1/ffn/layer_prepostprocess/layer_norm/layer_norm_scale_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/encoder/layer_1/ffn/layer_prepostprocess/layer_norm/layer_norm_bias:0 is illegal; using training_variables/transformer/body/encoder/layer_1/ffn/layer_prepostprocess/layer_norm/layer_norm_bias_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/encoder/layer_1/ffn/conv1/kernel:0 is illegal; using training_variables/transformer/body/encoder/layer_1/ffn/conv1/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/encoder/layer_1/ffn/conv1/bias:0 is illegal; using training_variables/transformer/body/encoder/layer_1/ffn/conv1/bias_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/encoder/layer_1/ffn/conv2/kernel:0 is illegal; using training_variables/transformer/body/encoder/layer_1/ffn/conv2/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/encoder/layer_1/ffn/conv2/bias:0 is illegal; using training_variables/transformer/body/encoder/layer_1/ffn/conv2/bias_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/encoder/layer_prepostprocess/layer_norm/layer_norm_scale:0 is illegal; using training_variables/transformer/body/encoder/layer_prepostprocess/layer_norm/layer_norm_scale_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/encoder/layer_prepostprocess/layer_norm/layer_norm_bias:0 is illegal; using training_variables/transformer/body/encoder/layer_prepostprocess/layer_norm/layer_norm_bias_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_0/self_attention/layer_prepostprocess/layer_norm/layer_norm_scale:0 is illegal; using training_variables/transformer/body/decoder/layer_0/self_attention/layer_prepostprocess/layer_norm/layer_norm_scale_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_0/self_attention/layer_prepostprocess/layer_norm/layer_norm_bias:0 is illegal; using training_variables/transformer/body/decoder/layer_0/self_attention/layer_prepostprocess/layer_norm/layer_norm_bias_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_0/self_attention/multihead_attention/q/kernel:0 is illegal; using training_variables/transformer/body/decoder/layer_0/self_attention/multihead_attention/q/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_0/self_attention/multihead_attention/k/kernel:0 is illegal; using training_variables/transformer/body/decoder/layer_0/self_attention/multihead_attention/k/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_0/self_attention/multihead_attention/v/kernel:0 is illegal; using training_variables/transformer/body/decoder/layer_0/self_attention/multihead_attention/v/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_0/self_attention/multihead_attention/output_transform/kernel:0 is illegal; using training_variables/transformer/body/decoder/layer_0/self_attention/multihead_attention/output_transform/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_0/encdec_attention/layer_prepostprocess/layer_norm/layer_norm_scale:0 is illegal; using training_variables/transformer/body/decoder/layer_0/encdec_attention/layer_prepostprocess/layer_norm/layer_norm_scale_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_0/encdec_attention/layer_prepostprocess/layer_norm/layer_norm_bias:0 is illegal; using training_variables/transformer/body/decoder/layer_0/encdec_attention/layer_prepostprocess/layer_norm/layer_norm_bias_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_0/encdec_attention/multihead_attention/q/kernel:0 is illegal; using training_variables/transformer/body/decoder/layer_0/encdec_attention/multihead_attention/q/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_0/encdec_attention/multihead_attention/k/kernel:0 is illegal; using training_variables/transformer/body/decoder/layer_0/encdec_attention/multihead_attention/k/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_0/encdec_attention/multihead_attention/v/kernel:0 is illegal; using training_variables/transformer/body/decoder/layer_0/encdec_attention/multihead_attention/v/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_0/encdec_attention/multihead_attention/output_transform/kernel:0 is illegal; using training_variables/transformer/body/decoder/layer_0/encdec_attention/multihead_attention/output_transform/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_0/ffn/layer_prepostprocess/layer_norm/layer_norm_scale:0 is illegal; using training_variables/transformer/body/decoder/layer_0/ffn/layer_prepostprocess/layer_norm/layer_norm_scale_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_0/ffn/layer_prepostprocess/layer_norm/layer_norm_bias:0 is illegal; using training_variables/transformer/body/decoder/layer_0/ffn/layer_prepostprocess/layer_norm/layer_norm_bias_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_0/ffn/conv1/kernel:0 is illegal; using training_variables/transformer/body/decoder/layer_0/ffn/conv1/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_0/ffn/conv1/bias:0 is illegal; using training_variables/transformer/body/decoder/layer_0/ffn/conv1/bias_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_0/ffn/conv2/kernel:0 is illegal; using training_variables/transformer/body/decoder/layer_0/ffn/conv2/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_0/ffn/conv2/bias:0 is illegal; using training_variables/transformer/body/decoder/layer_0/ffn/conv2/bias_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_1/self_attention/layer_prepostprocess/layer_norm/layer_norm_scale:0 is illegal; using training_variables/transformer/body/decoder/layer_1/self_attention/layer_prepostprocess/layer_norm/layer_norm_scale_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_1/self_attention/layer_prepostprocess/layer_norm/layer_norm_bias:0 is illegal; using training_variables/transformer/body/decoder/layer_1/self_attention/layer_prepostprocess/layer_norm/layer_norm_bias_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_1/self_attention/multihead_attention/q/kernel:0 is illegal; using training_variables/transformer/body/decoder/layer_1/self_attention/multihead_attention/q/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_1/self_attention/multihead_attention/k/kernel:0 is illegal; using training_variables/transformer/body/decoder/layer_1/self_attention/multihead_attention/k/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_1/self_attention/multihead_attention/v/kernel:0 is illegal; using training_variables/transformer/body/decoder/layer_1/self_attention/multihead_attention/v/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_1/self_attention/multihead_attention/output_transform/kernel:0 is illegal; using training_variables/transformer/body/decoder/layer_1/self_attention/multihead_attention/output_transform/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_1/encdec_attention/layer_prepostprocess/layer_norm/layer_norm_scale:0 is illegal; using training_variables/transformer/body/decoder/layer_1/encdec_attention/layer_prepostprocess/layer_norm/layer_norm_scale_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_1/encdec_attention/layer_prepostprocess/layer_norm/layer_norm_bias:0 is illegal; using training_variables/transformer/body/decoder/layer_1/encdec_attention/layer_prepostprocess/layer_norm/layer_norm_bias_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_1/encdec_attention/multihead_attention/q/kernel:0 is illegal; using training_variables/transformer/body/decoder/layer_1/encdec_attention/multihead_attention/q/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_1/encdec_attention/multihead_attention/k/kernel:0 is illegal; using training_variables/transformer/body/decoder/layer_1/encdec_attention/multihead_attention/k/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_1/encdec_attention/multihead_attention/v/kernel:0 is illegal; using training_variables/transformer/body/decoder/layer_1/encdec_attention/multihead_attention/v/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_1/encdec_attention/multihead_attention/output_transform/kernel:0 is illegal; using training_variables/transformer/body/decoder/layer_1/encdec_attention/multihead_attention/output_transform/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_1/ffn/layer_prepostprocess/layer_norm/layer_norm_scale:0 is illegal; using training_variables/transformer/body/decoder/layer_1/ffn/layer_prepostprocess/layer_norm/layer_norm_scale_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_1/ffn/layer_prepostprocess/layer_norm/layer_norm_bias:0 is illegal; using training_variables/transformer/body/decoder/layer_1/ffn/layer_prepostprocess/layer_norm/layer_norm_bias_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_1/ffn/conv1/kernel:0 is illegal; using training_variables/transformer/body/decoder/layer_1/ffn/conv1/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_1/ffn/conv1/bias:0 is illegal; using training_variables/transformer/body/decoder/layer_1/ffn/conv1/bias_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_1/ffn/conv2/kernel:0 is illegal; using training_variables/transformer/body/decoder/layer_1/ffn/conv2/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_1/ffn/conv2/bias:0 is illegal; using training_variables/transformer/body/decoder/layer_1/ffn/conv2/bias_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_prepostprocess/layer_norm/layer_norm_scale:0 is illegal; using training_variables/transformer/body/decoder/layer_prepostprocess/layer_norm/layer_norm_scale_0 instead.\n",
            "INFO:tensorflow:Summary name training_variables/transformer/body/decoder/layer_prepostprocess/layer_norm/layer_norm_bias:0 is illegal; using training_variables/transformer/body/decoder/layer_prepostprocess/layer_norm/layer_norm_bias_0 instead.\n",
            "INFO:tensorflow:Using optimizer Adam\n",
            ":::MLPv0.5.0 transformer 1541965487.211730480 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/optimize.py:45) opt_name: \"Adam\"\n",
            ":::MLPv0.5.0 transformer 1541965487.212942600 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/optimize.py:45) opt_hp_Adam_beta1: 0.9\n",
            ":::MLPv0.5.0 transformer 1541965487.214051008 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/optimize.py:45) opt_hp_Adam_beta2: 0.997\n",
            ":::MLPv0.5.0 transformer 1541965487.215129137 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/optimize.py:45) opt_hp_Adam_epsilon: 1e-09\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "2018-11-11 19:44:54.212397: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2018-11-11 19:44:54.212837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2018-11-11 19:44:54.212891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-11 19:44:54.567184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-11 19:44:54.567246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-11 19:44:54.567270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-11 19:44:54.567565: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2018-11-11 19:44:54.567628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /root/t2t_train/translate/model.ckpt.\n",
            "2018-11-11 19:45:14.114906: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:98] Filling up shuffle buffer (this may take a while): 429 of 512\n",
            "2018-11-11 19:45:15.834809: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:136] Shuffle buffer filled.\n",
            "INFO:tensorflow:loss = 9.4006195, step = 0\n",
            "INFO:tensorflow:global_step/sec: 3.57558\n",
            "INFO:tensorflow:loss = 8.412567, step = 100 (27.969 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.93779\n",
            "INFO:tensorflow:loss = 7.248451, step = 200 (25.395 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.88562\n",
            "INFO:tensorflow:loss = 6.1761093, step = 300 (25.736 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8732\n",
            "INFO:tensorflow:loss = 5.6164823, step = 400 (25.818 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.88148\n",
            "INFO:tensorflow:loss = 5.2906494, step = 500 (25.764 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.86821\n",
            "INFO:tensorflow:loss = 4.97867, step = 600 (25.852 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8729\n",
            "INFO:tensorflow:loss = 4.7850933, step = 700 (25.819 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.87862\n",
            "INFO:tensorflow:loss = 4.4791656, step = 800 (25.783 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.83393\n",
            "INFO:tensorflow:loss = 4.280194, step = 900 (26.083 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1000 into /root/t2t_train/translate/model.ckpt.\n",
            "INFO:tensorflow:Reading data files from /root/t2t_data/translate_enfr_wmt_small32k-dev*\n",
            "INFO:tensorflow:partition: 0 num_data_files: 1\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
            "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
            "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
            ":::MLPv0.5.0 transformer 1541965780.241218328 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/t2t_model.py:213) model_hp_initializer_gain: 1.0\n",
            "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
            "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_27927_256.bottom\n",
            "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_27927_256.targets_bottom\n",
            "INFO:tensorflow:Building model body\n",
            ":::MLPv0.5.0 transformer 1541965780.591640234 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541965780.593917608 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
            ":::MLPv0.5.0 transformer 1541965780.596545219 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_num_heads: 4\n",
            ":::MLPv0.5.0 transformer 1541965780.599025726 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541965781.185400248 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_ffn_filter: {\"filter_size\": 1024, \"use_bias\": \"True\", \"activation\": \"relu\"}\n",
            ":::MLPv0.5.0 transformer 1541965781.187844515 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_ffn_dense: {\"hidden_size\": 256, \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1541965781.189958572 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541965781.598738194 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_ffn_filter: {\"filter_size\": 1024, \"use_bias\": \"True\", \"activation\": \"relu\"}\n",
            ":::MLPv0.5.0 transformer 1541965781.601131439 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_ffn_dense: {\"hidden_size\": 256, \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1541965781.604200125 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541965781.714870453 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 256}\n",
            ":::MLPv0.5.0 transformer 1541965781.846468925 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541965781.848765850 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
            ":::MLPv0.5.0 transformer 1541965781.850677490 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_num_heads: 4\n",
            ":::MLPv0.5.0 transformer 1541965781.852567196 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541965782.376133680 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:1290) model_hp_ffn_filter: {\"filter_size\": 1024, \"use_bias\": \"True\", \"activation\": \"relu\"}\n",
            ":::MLPv0.5.0 transformer 1541965782.378046989 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:1290) model_hp_ffn_dense: {\"hidden_size\": 256, \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1541965782.380056858 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:1290) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541965782.963706732 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:1290) model_hp_ffn_filter: {\"filter_size\": 1024, \"use_bias\": \"True\", \"activation\": \"relu\"}\n",
            ":::MLPv0.5.0 transformer 1541965782.965867043 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:1290) model_hp_ffn_dense: {\"hidden_size\": 256, \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1541965782.967926025 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:1290) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541965783.048824072 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 256}\n",
            "INFO:tensorflow:Transforming body output with symbol_modality_27927_256.top\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-11-11-19:49:44\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "2018-11-11 19:49:44.560238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-11 19:49:44.560309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-11 19:49:44.560336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-11 19:49:44.560370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-11 19:49:44.560578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from /root/t2t_train/translate/model.ckpt-1000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [1/10]\n",
            "INFO:tensorflow:Evaluation [2/10]\n",
            "INFO:tensorflow:Evaluation [3/10]\n",
            "INFO:tensorflow:Evaluation [4/10]\n",
            "INFO:tensorflow:Evaluation [5/10]\n",
            "INFO:tensorflow:Evaluation [6/10]\n",
            "INFO:tensorflow:Evaluation [7/10]\n",
            "INFO:tensorflow:Evaluation [8/10]\n",
            "INFO:tensorflow:Evaluation [9/10]\n",
            "INFO:tensorflow:Evaluation [10/10]\n",
            "INFO:tensorflow:Finished evaluation at 2018-11-11-19:49:46\n",
            "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 4.327046, metrics-translate_enfr_wmt_small32k/targets/accuracy = 0.32380953, metrics-translate_enfr_wmt_small32k/targets/accuracy_per_sequence = 0.0, metrics-translate_enfr_wmt_small32k/targets/accuracy_top5 = 0.49275362, metrics-translate_enfr_wmt_small32k/targets/approx_bleu_score = 0.04884533, metrics-translate_enfr_wmt_small32k/targets/neg_log_perplexity = -4.3688664, metrics-translate_enfr_wmt_small32k/targets/rouge_2_fscore = 0.13524505, metrics-translate_enfr_wmt_small32k/targets/rouge_L_fscore = 0.35872638\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /root/t2t_train/translate/model.ckpt-1000\n",
            "INFO:tensorflow:global_step/sec: 2.66796\n",
            "INFO:tensorflow:loss = 4.2106857, step = 1000 (37.482 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.90392\n",
            "INFO:tensorflow:loss = 4.198671, step = 1100 (25.615 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.85627\n",
            "INFO:tensorflow:loss = 3.890377, step = 1200 (25.932 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.85726\n",
            "INFO:tensorflow:loss = 3.9685266, step = 1300 (25.925 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.83579\n",
            "INFO:tensorflow:loss = 3.858393, step = 1400 (26.070 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.86152\n",
            "INFO:tensorflow:loss = 3.7364838, step = 1500 (25.897 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.88404\n",
            "INFO:tensorflow:loss = 3.510896, step = 1600 (25.746 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.9053\n",
            "INFO:tensorflow:loss = 3.1713893, step = 1700 (25.607 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.84962\n",
            "INFO:tensorflow:loss = 3.4728298, step = 1800 (25.976 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.89796\n",
            "INFO:tensorflow:loss = 3.4082236, step = 1900 (25.658 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 2000 into /root/t2t_train/translate/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 3.75456\n",
            "INFO:tensorflow:loss = 3.4607177, step = 2000 (26.630 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.82719\n",
            "INFO:tensorflow:loss = 3.0347316, step = 2100 (26.129 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.74999\n",
            "INFO:tensorflow:loss = 3.2158654, step = 2200 (26.668 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.89544\n",
            "INFO:tensorflow:loss = 3.1863382, step = 2300 (25.670 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8741\n",
            "INFO:tensorflow:loss = 3.2395647, step = 2400 (25.813 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.86378\n",
            "INFO:tensorflow:loss = 3.01034, step = 2500 (25.881 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.89543\n",
            "INFO:tensorflow:loss = 2.9749746, step = 2600 (25.672 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.84803\n",
            "INFO:tensorflow:loss = 2.9514368, step = 2700 (25.987 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.85391\n",
            "INFO:tensorflow:loss = 2.5009024, step = 2800 (25.948 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8419\n",
            "INFO:tensorflow:loss = 2.778212, step = 2900 (26.030 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 3000 into /root/t2t_train/translate/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 3.76439\n",
            "INFO:tensorflow:loss = 3.0243793, step = 3000 (26.564 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.84868\n",
            "INFO:tensorflow:loss = 2.604603, step = 3100 (25.983 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.86875\n",
            "INFO:tensorflow:loss = 2.6993222, step = 3200 (25.848 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.88943\n",
            "INFO:tensorflow:loss = 2.0814915, step = 3300 (25.710 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.88619\n",
            "INFO:tensorflow:loss = 2.5853176, step = 3400 (25.732 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.86642\n",
            "INFO:tensorflow:loss = 2.1270075, step = 3500 (25.864 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.89041\n",
            "INFO:tensorflow:loss = 2.5170121, step = 3600 (25.704 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.89505\n",
            "INFO:tensorflow:loss = 2.6085956, step = 3700 (25.674 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.86787\n",
            "INFO:tensorflow:loss = 2.4740624, step = 3800 (25.856 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.82302\n",
            "INFO:tensorflow:loss = 2.4904473, step = 3900 (26.155 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 4000 into /root/t2t_train/translate/model.ckpt.\n",
            "INFO:tensorflow:Reading data files from /root/t2t_data/translate_enfr_wmt_small32k-dev*\n",
            "INFO:tensorflow:partition: 0 num_data_files: 1\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
            "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
            "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
            ":::MLPv0.5.0 transformer 1541966569.590221405 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/t2t_model.py:213) model_hp_initializer_gain: 1.0\n",
            "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
            "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_27927_256.bottom\n",
            "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_27927_256.targets_bottom\n",
            "INFO:tensorflow:Building model body\n",
            ":::MLPv0.5.0 transformer 1541966569.977028370 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541966569.980144739 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
            ":::MLPv0.5.0 transformer 1541966569.982553959 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_num_heads: 4\n",
            ":::MLPv0.5.0 transformer 1541966569.985263586 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541966570.291047096 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_ffn_filter: {\"filter_size\": 1024, \"use_bias\": \"True\", \"activation\": \"relu\"}\n",
            ":::MLPv0.5.0 transformer 1541966570.293263435 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_ffn_dense: {\"hidden_size\": 256, \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1541966570.295513868 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541966570.661298990 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_ffn_filter: {\"filter_size\": 1024, \"use_bias\": \"True\", \"activation\": \"relu\"}\n",
            ":::MLPv0.5.0 transformer 1541966570.663331509 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_ffn_dense: {\"hidden_size\": 256, \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1541966570.665262222 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541966570.769068003 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 256}\n",
            ":::MLPv0.5.0 transformer 1541966570.900238037 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541966570.902576923 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
            ":::MLPv0.5.0 transformer 1541966570.904730558 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_num_heads: 4\n",
            ":::MLPv0.5.0 transformer 1541966570.906820059 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541966571.422319174 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:1290) model_hp_ffn_filter: {\"filter_size\": 1024, \"use_bias\": \"True\", \"activation\": \"relu\"}\n",
            ":::MLPv0.5.0 transformer 1541966571.424413204 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:1290) model_hp_ffn_dense: {\"hidden_size\": 256, \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1541966571.426445961 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:1290) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541966572.504009485 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:1290) model_hp_ffn_filter: {\"filter_size\": 1024, \"use_bias\": \"True\", \"activation\": \"relu\"}\n",
            ":::MLPv0.5.0 transformer 1541966572.505987883 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:1290) model_hp_ffn_dense: {\"hidden_size\": 256, \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1541966572.507987261 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:1290) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541966572.589868307 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 256}\n",
            "INFO:tensorflow:Transforming body output with symbol_modality_27927_256.top\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-11-11-20:02:53\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "2018-11-11 20:02:53.802145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-11 20:02:53.802219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-11 20:02:53.802308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-11 20:02:53.802333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-11 20:02:53.802581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from /root/t2t_train/translate/model.ckpt-4000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [1/10]\n",
            "INFO:tensorflow:Evaluation [2/10]\n",
            "INFO:tensorflow:Evaluation [3/10]\n",
            "INFO:tensorflow:Evaluation [4/10]\n",
            "INFO:tensorflow:Evaluation [5/10]\n",
            "INFO:tensorflow:Evaluation [6/10]\n",
            "INFO:tensorflow:Evaluation [7/10]\n",
            "INFO:tensorflow:Evaluation [8/10]\n",
            "INFO:tensorflow:Evaluation [9/10]\n",
            "INFO:tensorflow:Evaluation [10/10]\n",
            "INFO:tensorflow:Finished evaluation at 2018-11-11-20:02:55\n",
            "INFO:tensorflow:Saving dict for global step 4000: global_step = 4000, loss = 1.9700735, metrics-translate_enfr_wmt_small32k/targets/accuracy = 0.5966874, metrics-translate_enfr_wmt_small32k/targets/accuracy_per_sequence = 0.027522936, metrics-translate_enfr_wmt_small32k/targets/accuracy_top5 = 0.7979296, metrics-translate_enfr_wmt_small32k/targets/approx_bleu_score = 0.28345457, metrics-translate_enfr_wmt_small32k/targets/neg_log_perplexity = -2.0466444, metrics-translate_enfr_wmt_small32k/targets/rouge_2_fscore = 0.37020335, metrics-translate_enfr_wmt_small32k/targets/rouge_L_fscore = 0.5891174\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: /root/t2t_train/translate/model.ckpt-4000\n",
            "INFO:tensorflow:global_step/sec: 2.72875\n",
            "INFO:tensorflow:loss = 2.6423216, step = 4000 (36.646 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.82406\n",
            "INFO:tensorflow:loss = 2.644252, step = 4100 (26.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.83355\n",
            "INFO:tensorflow:loss = 2.36273, step = 4200 (26.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.89792\n",
            "INFO:tensorflow:loss = 2.6788898, step = 4300 (25.655 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.84819\n",
            "INFO:tensorflow:loss = 2.8256075, step = 4400 (25.988 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.85869\n",
            "INFO:tensorflow:loss = 3.3462834, step = 4500 (25.915 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8629\n",
            "INFO:tensorflow:loss = 2.6353817, step = 4600 (25.887 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.88427\n",
            "INFO:tensorflow:loss = 2.2431698, step = 4700 (25.746 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.82006\n",
            "INFO:tensorflow:loss = 1.7053995, step = 4800 (26.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.87738\n",
            "INFO:tensorflow:loss = 2.5315518, step = 4900 (25.791 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into /root/t2t_train/translate/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 3.74945\n",
            "INFO:tensorflow:loss = 1.9810215, step = 5000 (26.670 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.86197\n",
            "INFO:tensorflow:loss = 2.066215, step = 5100 (25.894 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.90885\n",
            "INFO:tensorflow:loss = 2.3024993, step = 5200 (25.583 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.87656\n",
            "INFO:tensorflow:loss = 2.1946595, step = 5300 (25.797 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.89056\n",
            "INFO:tensorflow:loss = 1.959192, step = 5400 (25.703 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.85354\n",
            "INFO:tensorflow:loss = 2.241928, step = 5500 (25.951 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8617\n",
            "INFO:tensorflow:loss = 2.1646485, step = 5600 (25.897 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.85865\n",
            "INFO:tensorflow:loss = 2.5886362, step = 5700 (25.913 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.85644\n",
            "INFO:tensorflow:loss = 1.5300554, step = 5800 (25.931 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.86392\n",
            "INFO:tensorflow:loss = 2.2935631, step = 5900 (25.880 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 6000 into /root/t2t_train/translate/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 3.73572\n",
            "INFO:tensorflow:loss = 2.1860583, step = 6000 (26.769 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.88783\n",
            "INFO:tensorflow:loss = 2.0321214, step = 6100 (25.722 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.90978\n",
            "INFO:tensorflow:loss = 1.9860123, step = 6200 (25.577 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8689\n",
            "INFO:tensorflow:loss = 2.049748, step = 6300 (25.847 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.84305\n",
            "INFO:tensorflow:loss = 1.9791392, step = 6400 (26.020 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.83679\n",
            "INFO:tensorflow:loss = 2.0281081, step = 6500 (26.064 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.84912\n",
            "INFO:tensorflow:loss = 1.9852158, step = 6600 (25.980 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.86546\n",
            "INFO:tensorflow:loss = 2.1511807, step = 6700 (25.870 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.90027\n",
            "INFO:tensorflow:loss = 2.3211913, step = 6800 (25.639 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.87342\n",
            "INFO:tensorflow:loss = 1.7277781, step = 6900 (25.817 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 7000 into /root/t2t_train/translate/model.ckpt.\n",
            "INFO:tensorflow:Reading data files from /root/t2t_data/translate_enfr_wmt_small32k-dev*\n",
            "INFO:tensorflow:partition: 0 num_data_files: 1\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
            "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
            "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
            ":::MLPv0.5.0 transformer 1541967358.289026022 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/t2t_model.py:213) model_hp_initializer_gain: 1.0\n",
            "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
            "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_27927_256.bottom\n",
            "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_27927_256.targets_bottom\n",
            "INFO:tensorflow:Building model body\n",
            ":::MLPv0.5.0 transformer 1541967358.652831078 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541967358.654788017 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
            ":::MLPv0.5.0 transformer 1541967358.656604052 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_num_heads: 4\n",
            ":::MLPv0.5.0 transformer 1541967358.658494473 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541967359.474473953 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_ffn_filter: {\"filter_size\": 1024, \"use_bias\": \"True\", \"activation\": \"relu\"}\n",
            ":::MLPv0.5.0 transformer 1541967359.476692677 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_ffn_dense: {\"hidden_size\": 256, \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1541967359.478755951 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541967359.862666607 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_ffn_filter: {\"filter_size\": 1024, \"use_bias\": \"True\", \"activation\": \"relu\"}\n",
            ":::MLPv0.5.0 transformer 1541967359.864734173 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_ffn_dense: {\"hidden_size\": 256, \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1541967359.866858959 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541967359.970839500 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 256}\n",
            ":::MLPv0.5.0 transformer 1541967360.091170311 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541967360.093368530 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
            ":::MLPv0.5.0 transformer 1541967360.095445395 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_num_heads: 4\n",
            ":::MLPv0.5.0 transformer 1541967360.097327948 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541967360.627716541 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:1290) model_hp_ffn_filter: {\"filter_size\": 1024, \"use_bias\": \"True\", \"activation\": \"relu\"}\n",
            ":::MLPv0.5.0 transformer 1541967360.629815578 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:1290) model_hp_ffn_dense: {\"hidden_size\": 256, \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1541967360.631866932 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:1290) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541967361.225479364 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:1290) model_hp_ffn_filter: {\"filter_size\": 1024, \"use_bias\": \"True\", \"activation\": \"relu\"}\n",
            ":::MLPv0.5.0 transformer 1541967361.227679491 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:1290) model_hp_ffn_dense: {\"hidden_size\": 256, \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1541967361.229824305 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:1290) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541967361.312892437 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 256}\n",
            "INFO:tensorflow:Transforming body output with symbol_modality_27927_256.top\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-11-11-20:16:02\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "2018-11-11 20:16:02.876283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-11 20:16:02.876347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-11 20:16:02.876397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-11 20:16:02.876420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-11 20:16:02.876617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from /root/t2t_train/translate/model.ckpt-7000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [1/10]\n",
            "INFO:tensorflow:Evaluation [2/10]\n",
            "INFO:tensorflow:Evaluation [3/10]\n",
            "INFO:tensorflow:Evaluation [4/10]\n",
            "INFO:tensorflow:Evaluation [5/10]\n",
            "INFO:tensorflow:Evaluation [6/10]\n",
            "INFO:tensorflow:Evaluation [7/10]\n",
            "INFO:tensorflow:Evaluation [8/10]\n",
            "INFO:tensorflow:Evaluation [9/10]\n",
            "INFO:tensorflow:Evaluation [10/10]\n",
            "INFO:tensorflow:Finished evaluation at 2018-11-11-20:16:04\n",
            "INFO:tensorflow:Saving dict for global step 7000: global_step = 7000, loss = 1.5422798, metrics-translate_enfr_wmt_small32k/targets/accuracy = 0.65755695, metrics-translate_enfr_wmt_small32k/targets/accuracy_per_sequence = 0.059633028, metrics-translate_enfr_wmt_small32k/targets/accuracy_top5 = 0.8459627, metrics-translate_enfr_wmt_small32k/targets/approx_bleu_score = 0.37716246, metrics-translate_enfr_wmt_small32k/targets/neg_log_perplexity = -1.625432, metrics-translate_enfr_wmt_small32k/targets/rouge_2_fscore = 0.45827332, metrics-translate_enfr_wmt_small32k/targets/rouge_L_fscore = 0.6461409\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7000: /root/t2t_train/translate/model.ckpt-7000\n",
            "INFO:tensorflow:global_step/sec: 2.69447\n",
            "INFO:tensorflow:loss = 1.9287486, step = 7000 (37.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.90927\n",
            "INFO:tensorflow:loss = 1.9774177, step = 7100 (25.580 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.83399\n",
            "INFO:tensorflow:loss = 2.2243793, step = 7200 (26.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.85543\n",
            "INFO:tensorflow:loss = 1.8505517, step = 7300 (25.937 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.85028\n",
            "INFO:tensorflow:loss = 1.9758284, step = 7400 (25.972 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.83933\n",
            "INFO:tensorflow:loss = 2.1340594, step = 7500 (26.046 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.86696\n",
            "INFO:tensorflow:loss = 2.1089022, step = 7600 (25.861 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.85726\n",
            "INFO:tensorflow:loss = 2.0875375, step = 7700 (25.925 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.85256\n",
            "INFO:tensorflow:loss = 1.876936, step = 7800 (25.959 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.84989\n",
            "INFO:tensorflow:loss = 1.644337, step = 7900 (25.973 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 8000 into /root/t2t_train/translate/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 3.70643\n",
            "INFO:tensorflow:loss = 1.7315606, step = 8000 (26.979 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.81553\n",
            "INFO:tensorflow:loss = 2.0736213, step = 8100 (26.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.87721\n",
            "INFO:tensorflow:loss = 2.0274773, step = 8200 (25.791 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.89758\n",
            "INFO:tensorflow:loss = 1.9260327, step = 8300 (25.657 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.85865\n",
            "INFO:tensorflow:loss = 1.956434, step = 8400 (25.916 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.85179\n",
            "INFO:tensorflow:loss = 2.1153364, step = 8500 (25.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.87483\n",
            "INFO:tensorflow:loss = 1.8132759, step = 8600 (25.807 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.84854\n",
            "INFO:tensorflow:loss = 1.9286745, step = 8700 (25.984 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8899\n",
            "INFO:tensorflow:loss = 1.73284, step = 8800 (25.708 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.86692\n",
            "INFO:tensorflow:loss = 1.7273281, step = 8900 (25.860 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 9000 into /root/t2t_train/translate/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 3.73659\n",
            "INFO:tensorflow:loss = 1.8242189, step = 9000 (26.762 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.82802\n",
            "INFO:tensorflow:loss = 1.8266497, step = 9100 (26.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8581\n",
            "INFO:tensorflow:loss = 1.5997366, step = 9200 (25.920 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.86366\n",
            "INFO:tensorflow:loss = 1.8034651, step = 9300 (25.881 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.87375\n",
            "INFO:tensorflow:loss = 1.7202817, step = 9400 (25.815 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.87459\n",
            "INFO:tensorflow:loss = 2.6199465, step = 9500 (25.810 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.84484\n",
            "INFO:tensorflow:loss = 2.0892608, step = 9600 (26.008 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.84971\n",
            "INFO:tensorflow:loss = 2.0114822, step = 9700 (25.976 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.87428\n",
            "INFO:tensorflow:loss = 1.5491395, step = 9800 (25.811 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.88546\n",
            "INFO:tensorflow:loss = 1.4730827, step = 9900 (25.738 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /root/t2t_train/translate/model.ckpt.\n",
            "INFO:tensorflow:Reading data files from /root/t2t_data/translate_enfr_wmt_small32k-dev*\n",
            "INFO:tensorflow:partition: 0 num_data_files: 1\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
            "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
            "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
            ":::MLPv0.5.0 transformer 1541968148.461330652 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/t2t_model.py:213) model_hp_initializer_gain: 1.0\n",
            "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
            "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_27927_256.bottom\n",
            "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_27927_256.targets_bottom\n",
            "INFO:tensorflow:Building model body\n",
            ":::MLPv0.5.0 transformer 1541968148.837373972 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541968148.839416742 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
            ":::MLPv0.5.0 transformer 1541968148.841235638 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_num_heads: 4\n",
            ":::MLPv0.5.0 transformer 1541968148.843042135 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541968149.130156517 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_ffn_filter: {\"filter_size\": 1024, \"use_bias\": \"True\", \"activation\": \"relu\"}\n",
            ":::MLPv0.5.0 transformer 1541968149.132392168 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_ffn_dense: {\"hidden_size\": 256, \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1541968149.134325266 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541968149.518997669 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_ffn_filter: {\"filter_size\": 1024, \"use_bias\": \"True\", \"activation\": \"relu\"}\n",
            ":::MLPv0.5.0 transformer 1541968149.521071196 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_ffn_dense: {\"hidden_size\": 256, \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1541968149.523392200 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541968149.629786015 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 256}\n",
            ":::MLPv0.5.0 transformer 1541968149.751826286 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541968149.753982306 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
            ":::MLPv0.5.0 transformer 1541968149.755824089 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_num_heads: 4\n",
            ":::MLPv0.5.0 transformer 1541968149.757789373 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541968150.765983343 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:1290) model_hp_ffn_filter: {\"filter_size\": 1024, \"use_bias\": \"True\", \"activation\": \"relu\"}\n",
            ":::MLPv0.5.0 transformer 1541968150.768079519 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:1290) model_hp_ffn_dense: {\"hidden_size\": 256, \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1541968150.770051479 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:1290) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541968151.376645565 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:1290) model_hp_ffn_filter: {\"filter_size\": 1024, \"use_bias\": \"True\", \"activation\": \"relu\"}\n",
            ":::MLPv0.5.0 transformer 1541968151.378825665 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:1290) model_hp_ffn_dense: {\"hidden_size\": 256, \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1541968151.381025076 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:1290) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1541968151.473637104 (/usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 256}\n",
            "INFO:tensorflow:Transforming body output with symbol_modality_27927_256.top\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-11-11-20:29:12\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "2018-11-11 20:29:12.727860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-11 20:29:12.727944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-11 20:29:12.728076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-11 20:29:12.728098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-11 20:29:12.728342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from /root/t2t_train/translate/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [1/10]\n",
            "INFO:tensorflow:Evaluation [2/10]\n",
            "INFO:tensorflow:Evaluation [3/10]\n",
            "INFO:tensorflow:Evaluation [4/10]\n",
            "INFO:tensorflow:Evaluation [5/10]\n",
            "INFO:tensorflow:Evaluation [6/10]\n",
            "INFO:tensorflow:Evaluation [7/10]\n",
            "INFO:tensorflow:Evaluation [8/10]\n",
            "INFO:tensorflow:Evaluation [9/10]\n",
            "INFO:tensorflow:Evaluation [10/10]\n",
            "INFO:tensorflow:Finished evaluation at 2018-11-11-20:29:14\n",
            "INFO:tensorflow:Saving dict for global step 10000: global_step = 10000, loss = 1.3950846, metrics-translate_enfr_wmt_small32k/targets/accuracy = 0.68654245, metrics-translate_enfr_wmt_small32k/targets/accuracy_per_sequence = 0.06422018, metrics-translate_enfr_wmt_small32k/targets/accuracy_top5 = 0.8691511, metrics-translate_enfr_wmt_small32k/targets/approx_bleu_score = 0.4043045, metrics-translate_enfr_wmt_small32k/targets/neg_log_perplexity = -1.4670808, metrics-translate_enfr_wmt_small32k/targets/rouge_2_fscore = 0.4839282, metrics-translate_enfr_wmt_small32k/targets/rouge_L_fscore = 0.6669331\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /root/t2t_train/translate/model.ckpt-10000\n",
            "INFO:tensorflow:global_step/sec: 2.71563\n",
            "INFO:tensorflow:loss = 1.883144, step = 10000 (36.823 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.86894\n",
            "INFO:tensorflow:loss = 1.803751, step = 10100 (25.848 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.86245\n",
            "INFO:tensorflow:loss = 2.0578556, step = 10200 (25.890 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.85155\n",
            "INFO:tensorflow:loss = 1.7835536, step = 10300 (25.963 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.86412\n",
            "INFO:tensorflow:loss = 2.0973032, step = 10400 (25.880 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.85899\n",
            "INFO:tensorflow:loss = 1.7549232, step = 10500 (25.913 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.84423\n",
            "INFO:tensorflow:loss = 1.6470401, step = 10600 (26.013 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.84361\n",
            "INFO:tensorflow:loss = 1.6800432, step = 10700 (26.018 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.89042\n",
            "INFO:tensorflow:loss = 1.8400809, step = 10800 (25.704 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.84737\n",
            "INFO:tensorflow:loss = 1.606409, step = 10900 (25.992 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 11000 into /root/t2t_train/translate/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 3.69388\n",
            "INFO:tensorflow:loss = 1.8015693, step = 11000 (27.071 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.89432\n",
            "INFO:tensorflow:loss = 1.8567495, step = 11100 (25.679 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.85605\n",
            "INFO:tensorflow:loss = 1.676702, step = 11200 (25.934 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.84404\n",
            "INFO:tensorflow:loss = 1.7360528, step = 11300 (26.014 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8714\n",
            "INFO:tensorflow:loss = 1.9339365, step = 11400 (25.830 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80644\n",
            "INFO:tensorflow:loss = 1.8005162, step = 11500 (26.271 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8676\n",
            "INFO:tensorflow:loss = 1.7243878, step = 11600 (25.855 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.85619\n",
            "INFO:tensorflow:loss = 1.6160182, step = 11700 (25.933 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.86404\n",
            "INFO:tensorflow:loss = 2.1486082, step = 11800 (25.880 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80765\n",
            "INFO:tensorflow:loss = 1.730828, step = 11900 (26.262 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 12000 into /root/t2t_train/translate/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 3.70602\n",
            "INFO:tensorflow:loss = 1.6540982, step = 12000 (26.986 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.88907\n",
            "INFO:tensorflow:loss = 1.6880022, step = 12100 (25.710 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.85955\n",
            "INFO:tensorflow:loss = 1.6200901, step = 12200 (25.911 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.87595\n",
            "INFO:tensorflow:loss = 2.5066304, step = 12300 (25.800 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.82675\n",
            "INFO:tensorflow:loss = 1.6956606, step = 12400 (26.132 sec)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}